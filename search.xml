<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Storm 学习（二）起步]]></title>
    <url>%2F2018%2F09%2F05%2Fstorm-02%2F</url>
    <content type="text"><![CDATA[准备开始在本章，我们要创建一个 Storm 工程和我们的第一个 Storm 拓扑结构。 NOTE: 下面假设你的 JRE 版本在 1.6 以上。我们推荐 Oracle 提供的 JRE。你可以到 http://www.java.com/downloads/ 下载。 操作模式开始之前，有必要了解一下 Storm 的操作模式。有下面两种方式。 本地模式在本地模式下，Storm 拓扑结构运行在本地计算机的单一 JVM 进程上。这个模式用于开发、测试以及调试，因为这是观察所有组件如何协同工作的最简单方法。在这种模式下，我们可以调整参数，观察我们的拓扑结构如何在不同的 Storm 配置环境下运行。要在本地模式下运行，我们要下载 Storm 开发依赖，以便用来开发并测试我们的拓扑结构。我们创建了第一个 Storm 工程以后，很快就会明白如何使用本地模式了。 NOTE: 在本地模式下，跟在集群环境运行很像。不过很有必要确认一下所有组件都是线程安全的，因为当把它们部署到远程模式时它们可能会运行在不同的 JVM 进程甚至不同的物理机上，这个时候它们之间没有直接的通讯或共享内存。 我们要在本地模式运行本章的所有例子。 远程模式在远程模式下，我们向 Storm 集群提交拓扑，它通常由许多运行在不同机器上的流程组成。远程模式不会出现调试信息， 因此它也称作生产模式。不过在单一开发机上建立一个 Storm 集群是一个好主意，可以在部署到生产环境之前，用来确认拓扑在集群环境下没有任何问题。 你将在第六章学到更多关于远程模式的内容，并在附录B学到如何安装一个 Storm 集群。 Hello World我们在这个工程里创建一个简单的拓扑，数单词数量。我们可以把这个看作 Storm 的 “Hello World”。不过，这是一个非常强大的拓扑，因为它能够扩展到几乎无限大的规模，而且只需要做一些小修改，就能用它构建一个统计系统。举个例子，我们可以修改一下工程用来找出 Twitter 上的热点话题。 要创建这个拓扑，我们要用一个 spout 读取文本，第一个 bolt 用来标准化单词，第二个 bolt 为单词计数，如图2-1所示。你可以从这个网址下载源码压缩包， https://github.com/storm-book/examples-ch02-getting_started/zipball/master。 NOTE: 如果你使用 git（一个分布式版本控制与源码管理工具），你可以执行 git clone git@github.com:storm-book/examples-ch02-getting_started.git，把源码检出到你指定的目录。 Java 安装检查 构建 Storm 运行环境的第一步是检查你安装的 Java 版本。打开一个控制台窗口并执行命令：java -version。控制台应该会显示出类似如下的内容：123456java -versionjava version "1.6.0_26"Java(TM) SE Runtime Enviroment (build 1.6.0_26-b03)Java HotSpot(TM) Server VM (build 20.1-b02, mixed mode) 如果不是上述内容，检查你的 Java 安装情况。（参考 http://www.java.com/download/） 创建工程开始之前，先为这个应用建一个目录（就像你平常为 Java 应用做的那样）。这个目录用来存放工程源码。 接下来我们要下载 Storm 依赖包，这是一些 jar 包，我们要把它们添加到应用类路径中。你可以采用如下两种方式之一完成这一步： 下载所有依赖，解压缩它们，把它 们添加到类路径 使用 Apache Maven NOTE: Maven 是一个软件项目管理的综合工具。它可以用来管理项目的开发周期的许多方面，从包依赖到版本发布过程。在这本书中，我们将广泛使用它。如果要检查是否已经安装了maven，在命令行运行 mvn。如果没有安装你可以从 http://maven.apache.org/download.html下载。 没有必要先成为一个 Maven 专家才能使用 Storm，不过了解一下关于 Maven 工作方式的基础知识仍然会对你有所帮助。你可以在 Apache Maven 的网站上找到更多的信息（http://maven.apache.org/）。 NOTE: Storm 的 Maven 依赖引用了运行 Storm 本地模式的所有库。 要运行我们的拓扑，我们可以编写一个包含基本组件的 pom.xml 文件。1234567891011121314151617181920212223242526272829303132333435363738&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;storm.book&lt;/groupId&gt; &lt;artifactId&gt;Getting-Started&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.6&lt;/source&gt; &lt;target&gt;1.6&lt;/target&gt; &lt;compilerVersion&gt;1.6&lt;/compilerVersion&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;clojars.org&lt;/id&gt; &lt;url&gt;http://clojars.org/repo&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;storm&lt;/groupId&gt; &lt;artifactId&gt;storm&lt;/artifactId&gt; &lt;version&gt;0.6.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 开头几行指定了工程名称和版本号。然后我们添加了一个编译器插件，告知 Maven 我们的代码要用 Java1.6 编译。接下来我们定义了 Maven 仓库（Maven 支持为同一个工程指定多个仓库）。clojars 是存放 Storm 依赖的仓库。Maven 会为运行本地模式自动下载必要的所有子包依赖。 一个典型的 Maven Java 工程会拥有如下结构：12345678我们的应用目录/ ├── pom.xml └── src └── main └── java | ├── spouts | └── bolts └── resources java 目录下的子目录包含我们的代码，我们把要统计单词数的文件保存在 resource 目录下。 NOTE：命令 mkdir -p 会创建所有需要的父目录。 创建我们的第一个 Topology我们将为运行单词计数创建所有必要的类。可能这个例子中的某些部分，现在无法讲的很清楚，不过我们会在随后的章节做进一步的讲解。Spoutpout WordReader 类实现了 IRichSpout 接口。我们将在第四章看到更多细节。WordReader负责从文件按行读取文本，并把文本行提供给第一个 bolt。 NOTE: 一个 spout 发布一个定义域列表。这个架构允许你使用不同的 bolts 从同一个spout 流读取数据，它们的输出也可作为其它 bolts 的定义域，以此类推。 例2-1包含 WordRead 类的完整代码（我们将会分析下述代码的每一部分）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/ 例2-1.src/main/java/spouts/WordReader.java / package spouts; import java.io.BufferedReader; import java.io.FileNotFoundException; import java.io.FileReader; import java.util.Map; import backtype.storm.spout.SpoutOutputCollector; import backtype.storm.task.TopologyContext; import backtype.storm.topology.IRichSpout; import backtype.storm.topology.OutputFieldsDeclarer; import backtype.storm.tuple.Fields; import backtype.storm.tuple.Values; public class WordReader implements IRichSpout &#123; private SpoutOutputCollector collector; private FileReader fileReader; private boolean completed = false; private TopologyContext context; public boolean isDistributed() &#123;return false;&#125; public void ack(Object msgId) &#123; System.out.println("OK:"+msgId); &#125; public void close() &#123;&#125; public void fail(Object msgId) &#123; System.out.println("FAIL:"+msgId); &#125; / 这个方法做的惟一一件事情就是分发文件中的文本行 / public void nextTuple() &#123; / 这个方法会不断的被调用，直到整个文件都读完了，我们将等待并返回。 / if(completed)&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; //什么也不做 &#125; return; &#125; String str; //创建reader BufferedReader reader = new BufferedReader(fileReader); try&#123; //读所有文本行 while((str = reader.readLine()) != null)&#123; / 按行发布一个新值 / this.collector.emit(new Values(str),str); &#125; &#125;catch(Exception e)&#123; throw new RuntimeException("Error reading tuple",e); &#125;finally&#123; completed = true; &#125; &#125; / 我们将创建一个文件并维持一个collector对象 / public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) &#123; try &#123; this.context = context; this.fileReader = new FileReader(conf.get("wordsFile").toString()); &#125; catch (FileNotFoundException e) &#123; throw new RuntimeException("Error reading file ["+conf.get("wordFile")+"]"); &#125; this.collector = collector; &#125; / 声明输入域"word" / public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; declarer.declare(new Fields("line")); &#125; &#125; 第一个被调用的 spout 方法都是 public void open(Map conf, TopologyContext context, SpoutOutputCollector collector)。它接收如下参数：配置对象，在定义topology 对象是创建；TopologyContext 对象，包含所有拓扑数据；还有SpoutOutputCollector 对象，它能让我们发布交给 bolts 处理的数据。下面的代码主是这个方法的实现。12345678910public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) &#123; try &#123; this.context = context; this.fileReader = new FileReader(conf.get("wordsFile").toString()); &#125; catch (FileNotFoundException e) &#123; throw new RuntimeException("Error reading file ["+conf.get("wordFile")+"]"); &#125; this.collector = collector;&#125; 我们在这个方法里创建了一个 FileReader 对象，用来读取文件。接下来我们要实现 public void nextTuple()，我们要通过它向 bolts 发布待处理的数据。在这个例子里，这个方法要读取文件并逐行发布数据。123456789101112131415161718192021public void nextTuple() &#123; if(completed)&#123; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; //什么也不做 &#125; return; &#125; String str; BufferedReader reader = new BufferedReader(fileReader); try&#123; while((str = reader.readLine()) != null)&#123; this.collector.emit(new Values(str)); &#125; &#125;catch(Exception e)&#123; throw new RuntimeException("Error reading tuple",e); &#125;finally&#123; completed = true; &#125;&#125; NOTE: Values 是一个 ArrarList 实现，它的元素就是传入构造器的参数。 nextTuple() 会在同一个循环内被 ack() 和 fail() 周期性的调用。没有任务时它必须释放对线程的控制，其它方法才有机会得以执行。因此 nextTuple 的第一行就要检查是否已处理完成。如果完成了，为了降低处理器负载，会在返回前休眠一毫秒。如果任务完成了，文件中的每一行都已被读出并分发了。 NOTE:元组(tuple)是一个具名值列表，它可以是任意 java 对象（只要它是可序列化的）。默认情况，Storm 会序列化字符串、字节数组、ArrayList、HashMap 和 HashSet 等类型。 Bolts现在我们有了一个 spout，用来按行读取文件并每行发布一个元组，还要创建两个 bolts，用来处理它们（看图2-1）。bolts 实现了接口 backtype.storm.topology.IRichBolt。 bolt最重要的方法是void execute(Tuple input)，每次接收到元组时都会被调用一次，还会再发布若干个元组。 NOTE: 只要必要，bolt 或 spout 会发布若干元组。当调用 nextTuple 或 execute 方法时，它们可能会发布0个、1个或许多个元组。你将在第五章学习更多这方面的内容。 第一个 bolt，WordNormalizer，负责得到并标准化每行文本。它把文本行切分成单词，大写转化成小写，去掉头尾空白符。 首先我们要声明 bolt 的出参：123public void declareOutputFields(OutputFieldsDeclarer declarer)&#123; declarer.declare(new Fields("word"));&#125; 这里我们声明 bolt 将发布一个名为 “word” 的域。 下一步我们实现 public void execute(Tuple input)，处理传入的元组：1234567891011121314public void execute(Tuple input)&#123; String sentence=input.getString(0); String[] words=sentence.split(" "); for(String word : words)&#123; word=word.trim(); if(!word.isEmpty())&#123; word=word.toLowerCase(); //发布这个单词 collector.emit(new Values(word)); &#125; &#125; //对元组做出应答 collector.ack(input);&#125; 第一行从元组读取值。值可以按位置或名称读取。接下来值被处理并用collector对象发布。最后，每次都调用collector 对象的 ack() 方法确认已成功处理了一个元组。 例2-2是这个类的完整代码。12345678910111213141516171819202122232425262728293031323334353637383940414243444546//例2-2 src/main/java/bolts/WordNormalizer.javapackage bolts;import java.util.ArrayList;import java.util.List;import java.util.Map;import backtype.storm.task.OutputCollector;import backtype.storm.task.TopologyContext;import backtype.storm.topology.IRichBolt;import backtype.storm.topology.OutputFieldsDeclarer;import backtype.storm.tuple.Fields;import backtype.storm.tuple.Tuple;import backtype.storm.tuple.Values;public class WordNormalizer implements IRichBolt&#123; private OutputCollector collector; public void cleanup()&#123;&#125; / bolt从单词文件接收到文本行，并标准化它。 文本行会全部转化成小写，并切分它，从中得到所有单词。 / public void execute(Tuple input)&#123; String sentence = input.getString(0); String[] words = sentence.split(" "); for(String word : words)&#123; word = word.trim(); if(!word.isEmpty())&#123; word=word.toLowerCase(); //发布这个单词 List a = new ArrayList(); a.add(input); collector.emit(a,new Values(word)); &#125; &#125; //对元组做出应答 collector.ack(input); &#125; public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) &#123; this.collector=collector; &#125; / 这个bolt只会发布“word”域 / public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; declarer.declare(new Fields("word")); &#125;&#125; NOTE:通过这个例子，我们了解了在一次 execute 调用中发布多个元组。如果这个方法在一次调用中接收到句子 “This is the Storm book”，它将会发布五个元组。 下一个bolt，WordCounter，负责为单词计数。这个拓扑结束时（cleanup() 方法被调用时），我们将显示每个单词的数量。 NOTE: 这个例子的 bolt 什么也没发布，它把数据保存在 map 里，但是在真实的场景中可以把数据保存到数据库。12345678910111213141516171819202122232425262728293031323334353637383940414243444546package bolts;import java.util.HashMap;import java.util.Map;import backtype.storm.task.OutputCollector;import backtype.storm.task.TopologyContext;import backtype.storm.topology.IRichBolt;import backtype.storm.topology.OutputFieldsDeclarer;import backtype.storm.tuple.Tuple;public class WordCounter implements IRichBolt&#123; Integer id; String name; Map counters; private OutputCollector collector; / 这个spout结束时（集群关闭的时候），我们会显示单词数量 / @Override public void cleanup()&#123; System.out.println("-- 单词数 【"+name+"-"+id+"】 --"); for(Map.Entry entry : counters.entrySet())&#123; System.out.println(entry.getKey()+": "+entry.getValue()); &#125; &#125; / 为每个单词计数 /@Overridepublic void execute(Tuple input) &#123; String str=input.getString(0); /** 如果单词尚不存在于map，我们就创建一个，如果已在，我们就为它加1 / if(!counters.containsKey(str))&#123; counters.put(str,1); &#125;else&#123; Integer c = counters.get(str) + 1; counters.put(str,c); &#125; //对元组作为应答 collector.ack(input);&#125; / 初始化 / @Override public void prepare(Map stormConf, TopologyContext context, OutputCollector collector)&#123; this.counters = new HashMap(); this.collector = collector; this.name = context.getThisComponentId(); this.id = context.getThisTaskId(); &#125; @Override public void declareOutputFields(OutputFieldsDeclarer declarer) &#123;&#125;&#125; execute 方法使用一个 map 收集单词并计数。拓扑结束时，将调用 clearup() 方法打印计数器 map。（虽然这只是一个例子，但是通常情况下，当拓扑关闭时，你应当使用 cleanup() 方法关闭活动的连接和其它资源。） 主类你可以在主类中创建拓扑和一个本地集群对象，以便于在本地测试和调试。LocalCluster 可以通过 Config 对象，让你尝试不同的集群配置。比如，当使用不同数量的工作进程测试你的拓扑时，如果不小心使用了某个全局变量或类变量，你就能够发现错误。（更多内容请见第三章） NOTE：所有拓扑节点的各个进程必须能够独立运行，而不依赖共享数据（也就是没有全局变量或类变量），因为当拓扑运行在真实的集群环境时，这些进程可能会运行在不同的机器上。 接下来，TopologyBuilder 将用来创建拓扑，它决定 Storm 如何安排各节点，以及它们交换数据的方式。 1234TopologyBuilder builder = new TopologyBuilder();builder.setSpout("word-reader", new WordReader());builder.setBolt("word-normalizer", new WordNormalizer()).shuffleGrouping("word-reader");builder.setBolt("word-counter", new WordCounter()).shuffleGrouping("word-normalizer"); 在 spout 和 bolts 之间通过 shuffleGrouping 方法连接。这种分组方式决定了 Storm 会以随机分配方式从源节点向目标节点发送消息。 下一步，创建一个包含拓扑配置的 Config 对象，它会在运行时与集群配置合并，并通过prepare 方法发送给所有节点。 123Config conf = new Config();conf.put("wordsFile", args[0]);conf.setDebug(true); 由 spout 读取的文件的文件名，赋值给 wordFile 属性。由于是在开发阶段，设置 debug 属性为 true，Strom 会打印节点间交换的所有消息，以及其它有助于理解拓扑运行方式的调试数据。 正如之前讲过的，你要用一个 LocalCluster 对象运行这个拓扑。在生产环境中，拓扑会持续运行，不过对于这个例子而言，你只要运行它几秒钟就能看到结果。1234LocalCluster cluster = new LocalCluster();cluster.submitTopology("Getting-Started-Topologie", conf, builder.createTopology());Thread.sleep(2000);cluster.shutdown(); 调用 createTopology 和 submitTopology，运行拓扑，休眠两秒钟（拓扑在另外的线程运行），然后关闭集群。 例2-3是完整的代码123456789101112131415161718192021222324252627282930//例2-3 src/main/java/TopologyMain.javaimport spouts.WordReader;import backtype.storm.Config;import backtype.storm.LocalCluster;import backtype.storm.topology.TopologyBuilder;import backtype.storm.tuple.Fields;import bolts.WordCounter;import bolts.WordNormalizer;public class TopologyMain &#123; public static void main(String[] args) throws InterruptedException &#123; //定义拓扑 TopologyBuilder builder = new TopologyBuilder()); builder.setSpout("word-reader", new WordReader()); builder.setBolt("word-normalizer", new WordNormalizer()).shuffleGrouping("word-reader"); builder.setBolt("word-counter", new WordCounter(),2).fieldsGrouping("word-normalizer", new Fields("word")); //配置 Config conf = new Config(); conf.put("wordsFile", args[0]); conf.setDebug(false); //运行拓扑 conf.put(Config.TOPOLOGY_MAX_SPOUT_PENDING, 1); LocalCluster cluster = new LocalCluster(); cluster.submitTopology("Getting-Started-Topologie", conf, builder.createTopology(); Thread.sleep(1000); cluster.shutdown(); &#125;&#125; 观察运行情况 你已经为运行你的第一个拓扑准备好了。在这个目录下面创建一个文件，/src/main/resources/words.txt，一个单词一行，然后用下面的命令运行这个拓扑：mvn exec:java -Dexec.mainClass=”TopologyMain” -Dexec.args=”src/main/resources/words.txt。举个例子，如果你的 words.txt 文件有如下内容： Storm test are great is an Storm simple application but very powerful really Storm is great 你应该会在日志中看到类似下面的内容： is: 2 application: 1 but: 1 great: 1 test: 1 simple: 1 Storm: 3 really: 1 are: 1 great: 1 an: 1 powerful: 1 very: 1 在这个例子中，每类节点只有一个实例。但是如果你有一个非常大的日志文件呢？你能够很轻松的改变系统中的节点数量实现并行工作。这个时候，你就要创建两个 WordCounter* 实例。1builder.setBolt("word-counter", new WordCounter(),2).shuffleGrouping("word-normalizer"); 程序返回时，你将看到： — 单词数 【word-counter-2】 — application: 1 is: 1 great: 1 are: 1 powerful: 1 Storm: 3 — 单词数 [word-counter-3] — really: 1 is: 1 but: 1 great: 1 test: 1 simple: 1 an: 1 very: 1 棒极了！修改并行度实在是太容易了（当然对于实际情况来说，每个实例都会运行在单独的机器上）。不过似乎有一个问题：单词 is 和 great 分别在每个 WordCounter 各计数一次。怎么会这样？当你调用shuffleGrouping 时，就决定了 Storm 会以随机分配的方式向你的 bolt 实例发送消息。在这个例子中，理想的做法是相同的单词问题发送给同一个 WordCounter 实例。你把shuffleGrouping(“word-normalizer”) 换成 fieldsGrouping(“word-normalizer”, new Fields(“word”)) 就能达到目的。试一试，重新运行程序，确认结果。 你将在后续章节学习更多分组方式和消息流类型。 结论我们已经讨论了 Storm 的本地和远程操作模式之间的不同，以及 Storm 的强大和易于开发的特性。你也学习了一些 Storm 的基本概念，我们将在后续章节深入讲解它们。]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>Storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Storm 学习（一） 基础知识]]></title>
    <url>%2F2018%2F09%2F05%2Fstorm-01%2F</url>
    <content type="text"><![CDATA[基础知识Storm 是一个分布式的，可靠的，容错的数据流处理系统。它会把工作任务委托给不同类型的组件，每个组件负责处理一项简单特定的任务。Storm 集群的输入流由一个被称作 spout 的组件管理，spout 把数据传递给 bolt， bolt 要么把数据保存到某种存储器，要么把数据传递给其它的 bolt。你可以想象一下，一个 Storm 集群就是在一连串的 bolt 之间转换 spout 传过来的数据。 这里用一个简单的例子来说明这个概念。昨晚我在新闻节目里看到主持人在谈论政治人物和他们对于各种政治话题的立场。他们一直重复着不同的名字，而我开始考虑这些名字是否被提到了相同的次数，以及不同次数之间的偏差。 想像播音员读的字幕作为你的数据输入流。你可以用一个 spout 读取一个文件（或者 socket，通过 HTTP，或者别的方法）。文本行被 spout 传给一个 bolt，再被 bolt 按单词切割。单词流又被传给另一个 bolt，在这里每个单词与一张政治人名列表比较。每遇到一个匹配的名字，第二个 bolt 为这个名字在数据库的计数加1。你可以随时查询数据库查看结果， 而且这些计数是随着数据到达实时更新的。 现在想象一下，很容易在整个 Storm 集群定义每个 bolt 和 spout 的并行性级别，因此你可以无限的扩展你的拓扑结构。很神奇，是吗？尽管这是个简单例子，你也可以看到 Storm 的强大。 有哪些典型的 Storm 应用案例？ 数据处理流 正如上例所展示的，不像其它的流处理系统，Storm 不需要中间队列。 连续计算 连续发送数据到客户端，使它们能够实时更新并显示结果，如网站指标。 分布式远程过程调用 频繁的 CPU 密集型操作并行化。 Storm 组件 对于一个Storm集群，一个连续运行的主节点组织若干节点工作。 在 Storm 集群中，有两类节点：主节点 master node 和工作节点 worker nodes。主节点运行着一个叫做 Nimbus 的守护进程。这个守护进程负责在集群中分发代码，为工作节点分配任务，并监控故障。Supervisor守护进程作为拓扑的一部分运行在工作节点上。一个 Storm 拓扑结构在不同的机器上运行着众多的工作节点。 因为 Storm 在 Zookeeper 或本地磁盘上维持所有的集群状态，守护进程可以是无状态的而且失效或重启时不会影响整个系统的健康 在系统底层，Storm 使用了 zeromq(0mq, zeromq(http://www.zeromq.org))。这是一种先进的，可嵌入的网络通讯库，它提供的绝妙功能使 Storm 成为可能。下面列出一些 zeromq 的特性。 一个并发架构的 Socket 库 对于集群产品和超级计算，比 TCP 要快 可通过 inproc（进程内）, IPC（进程间）, TCP 和 multicast(多播协议)通信 异步 I / O 的可扩展的多核消息传递应用程序 利用扇出(fanout), 发布订阅（PUB-SUB）,管道（pipeline）, 请求应答（REQ-REP），等方式实现 N-N 连接 NOTE: Storm 只用了 push/pull socketsStorm 的特性在所有这些设计思想与决策中，有一些非常棒的特性成就了独一无二的 Storm。 简化编程：如果你曾试着从零开始实现实时处理，你应该明白这是一件多么痛苦的事情。使用 Storm，复杂性被大大降低了。 使用一门基于 JVM 的语言开发会更容易，但是你可以借助一个小的中间件，在 Storm 上使用任何语言开发。有现成的中间件可供选择，当然也可以自己开发中间件。 容错：Storm 集群会关注工作节点状态，如果宕机了必要的时候会重新分配任务。 可扩展：所有你需要为扩展集群所做的工作就是增加机器。Storm 会在新机器就绪时向它们分配任务。 可靠的：所有消息都可保证至少处理一次。如果出错了，消息可能处理不只一次，不过你永远不会丢失消息。 快速：速度是驱动 Storm 设计的一个关键因素 事务性：You can get exactly once messaging semantics for pretty much any computation. 你可以为几乎任何计算得到恰好一次消息语义。]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>Storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用git将项目上传到github]]></title>
    <url>%2F2018%2F09%2F03%2Fgit-new%2F</url>
    <content type="text"><![CDATA[使用git将项目上传到github（最简单方法）首先你需要一个github账号，所有还没有的话先去注册吧！我们使用git需要先安装git工具，这里给出下载地址，下载后一路直接安装即可： 进入Github首页，点击New repository新建一个项目 填写相应信息后点击create即可Repository name: 仓库名称Description(可选): 仓库描述介绍Public, Private : 仓库权限（公开共享，私有或指定合作者）Initialize this repository with a README: 添加一个README.mdgitignore: 不需要进行版本管理的仓库类型，对应生成文件.gitignorelicense: 证书类型，对应生成文件LICENSE 点击Clone or dowload会出现一个地址，copy这个地址备用。 接下来就到本地操作了，首先右键你的项目，如果你之前安装git成功的话，右键会出现两个新选项，分别为Git Gui Here,Git Bash Here,这里我们选择Git Bash Here，进入如下界面，blog-hexo即为我的项目名。 接下来输入如下代码（关键步骤），把github上面的仓库克隆到本地git clone https://github.com/BlueWindQAQ/blog-hexo.git（https://github.com/BlueWindQAQ/blog-hexo.git替换成你之前复制的地址） 这个步骤以后你的本地项目文件夹下面就会多出个文件夹，该文件夹名即为你github上面的项目名，我们把本地项目文件夹下的所有文件（除了新多出的那个文件夹不用），其余都复制到那个新多出的文件夹下， 接下来依次输入以下代码即可完成其他剩余操作： git add . （注：别忘记后面的.，此操作是把文件夹下面的文件都添加进来）git commit -m “提交信息” （注：“提交信息”里面换成你需要，如“first commit”）git push -u origin master （注：此操作目的是把本地仓库push到github上面，此步骤需要你输入帐号和密码） 原文：https://www.cnblogs.com/cxk1995/p/5800196.html]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[针对innodb_flush_method参数的理解和对比测试（mycat+mysql）]]></title>
    <url>%2F2018%2F08%2F30%2Fmysql-innodb-flush-method%2F</url>
    <content type="text"><![CDATA[mysql的innodb_flush_method这个参数控制着innodb数据文件及redo log的打开、刷写模式，对于这个参数，文档上是这样描述的：有三个值：fdatasync(默认)，O_DSYNC，O_DIRECT默认是fdatasync，调用fsync()去刷数据文件与redo log的buffer为O_DSYNC时，innodb会使用O_SYNC方式打开和刷写redo log,使用fsync()刷写数据文件为O_DIRECT时，innodb使用O_DIRECT打开数据文件，使用fsync()刷写数据文件跟redo log首先文件的写操作包括三步：open,write,flush上面最常提到的fsync(int fd)函数，该函数作用是flush时将与fd文件描述符所指文件有关的buffer刷写到磁盘，并且flush完元数据信息(比如修改日期、创建日期等)才算flush成功。使用O_DSYNC方式打开redo文件表示当write日志时，数据都write到磁盘，并且元数据也需要更新，才返回成功。O_DIRECT则表示我们的write操作是从MySQL innodb buffer里直接向磁盘上写。 这三种模式写数据方式具体如下： fdatasync模式：写数据时，write这一步并不需要真正写到磁盘才算完成（可能写入到操作系统buffer中就会返回完成），真正完成是flush操作，buffer交给操作系统去flush,并且文件的元数据信息也都需要更新到磁盘。O_DSYNC模式：写日志操作是在write这步完成，而数据文件的写入是在flush这步通过fsync完成O_DIRECT模式：数据文件的写入操作是直接从mysql innodb buffer到磁盘的，并不用通过操作系统的缓冲，而真正的完成也是在flush这步,日志还是要经过OS缓冲 原文：https://blog.csdn.net/smooth00/article/details/72725941]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iostat数据中关于rKB/s 和wKB/s 列解读]]></title>
    <url>%2F2018%2F08%2F29%2Flinux-iostat%2F</url>
    <content type="text"><![CDATA[导引rKB/s 和wKB/s这两个参数,究竟怎么样才算是读写高1234567891011avg-cpu: %user %nice %system %iowait %steal %idle 36.04 0.00 14.47 1.78 0.00 47.72Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilvda 0.00 0.00 125.00 278.00 2000.00 11617.00 67.58 0.55 1.36 1.07 1.49 0.77 31.20avg-cpu: %user %nice %system %iowait %steal %idle 23.65 0.00 7.46 1.29 0.00 67.61Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilvda 0.00 0.00 71.00 271.00 1136.00 11287.00 72.65 0.53 1.55 1.17 1.65 0.77 26.40 含义: 而rKB/s 和wKB/s 列:每秒千字节为单位显示了读和写的数据量 如果这两对数据值都很高的话说明磁盘io操作是很频繁(注:高是怎么衡量的?) 两对数据值都很高的话说明磁盘io操作是很频繁]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>I/O</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webstorm 2018 激活破解方法]]></title>
    <url>%2F2018%2F08%2F29%2Fwebstorm-pojie%2F</url>
    <content type="text"><![CDATA[webstorm 作为最近最火的前端开发工具,也确实对得起那个价格,但是秉着勤俭节约的传统美德,我们肯定是能省则省啊。方法一注册时，在打开的License Activation窗口中选择“License server”，在输入框输入下面的网址：http://180.76.140.202:9123 (2018/07/20)http://idea.wrbugtest.tk/ (2018/06/16)点击：Activate即可。更多方法移步原文：https://blog.csdn.net/voke_/article/details/76418116]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>webstorm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[crontab命令]]></title>
    <url>%2F2018%2F08%2F29%2Flinux-crontab%2F</url>
    <content type="text"><![CDATA[crontab命令被用来提交和管理用户的需要周期性执行的任务，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。 语法1crontab(选项)(参数) 选项1234-e：编辑该用户的计时器设置；-l：列出该用户的计时器设置；-r：删除该用户的计时器设置；-u&lt;用户名称&gt;：指定要设定计时器的用户名称。 参数crontab文件：指定包含待执行任务的crontab文件。 知识扩展Linux下的任务调度分为两类：系统任务调度和用户任务调度。 系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。 /etc/crontab文件包括下面几行：123456789SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=""HOME=/# run-parts51 * * * * root run-parts /etc/cron.hourly24 7 * * * root run-parts /etc/cron.daily22 4 * * 0 root run-parts /etc/cron.weekly42 4 1 * * root run-parts /etc/cron.monthly 前四行是用来配置crond任务运行的环境变量，第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。 用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab文件都被保存在/var/spool/cron目录中。其文件名与用户名一致，使用者权限文件如下：123/etc/cron.deny 该文件中所列用户不允许使用crontab命令/etc/cron.allow 该文件中所列用户允许使用crontab命令/var/spool/cron/ 所有用户crontab文件存放的目录,以用户名命名 crontab文件的含义：用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下：1minute hour day month week command 顺序：分 时 日 月 周 其中： minute： 表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。在以上各个字段中，还可以使用以下特殊字符： 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 crond服务1234/sbin/service crond start //启动服务/sbin/service crond stop //关闭服务/sbin/service crond restart //重启服务/sbin/service crond reload //重新载入配置 查看crontab服务状态：1service crond status 手动启动crontab服务：1service crond start 查看crontab服务是否已设置为开机启动，执行命令：1ntsysv 加入开机自动启动：1chkconfig –level 35 crond on 实例每1分钟执行一次command1* * * * * command 每小时的第3和第15分钟执行13,15 * * * * command 在上午8点到11点的第3和第15分钟执行13,15 8-11 * * * command 每隔两天的上午8点到11点的第3和第15分钟执行13,15 8-11 */2 * * command 每个星期一的上午8点到11点的第3和第15分钟执行13,15 8-11 * * 1 command 每晚的21:30重启smb130 21 * * * /etc/init.d/smb restart 每月1、10、22日的4 : 45重启smb145 4 1,10,22 * * /etc/init.d/smb restart 每周六、周日的1:10重启smb110 1 * * 6,0 /etc/init.d/smb restart 每天18 : 00至23 : 00之间每隔30分钟重启smb10,30 18-23 * * * /etc/init.d/smb restart 每星期六的晚上11:00 pm重启smb10 23 * * 6 /etc/init.d/smb restart 每一小时重启smb1* */1 * * * /etc/init.d/smb restart 晚上11点到早上7点之间，每隔一小时重启smb1* 23-7/1 * * * /etc/init.d/smb restart 每月的4号与每周一到周三的11点重启smb10 11 4 * mon-wed /etc/init.d/smb restart 一月一号的4点重启smb10 4 1 jan * /etc/init.d/smb restart 每小时执行/etc/cron.hourly目录内的脚本101 * * * * root run-parts /etc/cron.hourly 原文：http://man.linuxde.net/crontab]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis哨兵模式]]></title>
    <url>%2F2018%2F08%2F28%2Fredis-sentinel%2F</url>
    <content type="text"><![CDATA[Redis Sentinel 模式简介Redis-Sentinel是官方推荐的高可用解决方案，当redis在做master-slave的高可用方案时，假如master宕机了，redis本身（以及其很多客户端）都没有实现自动进行主备切换，而redis-sentinel本身也是独立运行的进程，可以部署在其他与redis集群可通讯的机器中监控redis集群。 它的主要功能有一下几点1、不时地监控redis是否按照预期良好地运行;2、如果发现某个redis节点运行出现状况，能够通知另外一个进程(例如它的客户端);3、能够进行自动切换。当一个master节点不可用时，能够选举出master的多个slave(如果有超过一个slave的话)中的一个来作为新的master,其它的slave节点会将它所追随的master的地址改为被提升为master的slave的新地址。4、哨兵为客户端提供服务发现，客户端链接哨兵，哨兵提供当前master的地址然后提供服务，如果出现切换，也就是master挂了，哨兵会提供客户端一个新地址。 哨兵（sentinel）本身也是支持集群的很显然，单个哨兵会存在自己挂掉而无法监控整个集群的问题，所以哨兵也是支持集群的，我们通常用三台哨兵机器来监控一组redis集群。 快速开始！环境准备：centos7服务器3台,6也可以，没什么区别。我部署好了三台redis-1redis-2redis-3清空selinux与iptables 编译安装redis12345678910111213141516171819yum install gcc* tcl -ymkdir /opt/softcd /opt/softwget http://download.redis.io/releases/redis-3.2.4.tar.gztar xf redis-3.2.4.tar.gzcd redis-3.2.4makemkdir confmkdir bincp utils/redis_init_script bin/rediscp redis.conf conf/6379.confcd ..mv redis-3.2.4 /opt/rediscd /opt/redis/binsed -i s#CLIEXEC=\/usr\/local\/bin\/redis-cli#CLIEXEC=\/opt\/redis\/src\/redis-cli#g redissed -i s#EXEC=\/usr\/local\/bin\/redis-server#EXEC=\/opt\/redis\/src\/redis-server#g redissed -i s#CONF=\"\/etc\/redis#CONF=\"\/opt\/redis\/conf#g rediscd /opt/redis/confsed -i s#daemonize\ no#daemonize\ yes#g 6379.conf 安装完毕后，修改配置文件。vim /opt/redis/conf/6379.conf注释此条bind 127.0.0.1protected-mode yes 改为 protected-mode no #关闭安全模式至此，redis部署完毕。 redis的启动停止脚本在/opt/redis/bin/redis stop/startredis的配置文件在/opt/redis/conf/6379.confredis的登陆命令在/opt/redis/src/redis-cli redis配置主从启动两台redisredis-1 10.0.0.10redis-2 10.0.0.20 若redis-1为主的话，在redis-2的配置文件中配置slaveof 10.0.0.10 6379修改完毕后重启redis即可，重启后我们可通过登陆进入redis后info查看主从信息。 引入哨兵。redis-1与redis-2搭建完毕主从后，我们开始引入哨兵。哨兵是一个单独的程序，所以我们需要单独部署它。若是在其他机器上部署哨兵，那么请用上面的redis安装脚本重新安装一遍redis。在这里我已经部署完毕了redis-1redis-2redis-3 增加哨兵的配置文件。三台redis都需要增加，文件内容这三台一样。123456789vim /opt/redis/conf/sentinel.conf##sentinel for 10.0.0.10 ,its slave is 10.0.0.20#master1port 26383sentinel monitor master1 10.0.0.10 6379 2sentinel down-after-milliseconds master1 30000sentinel failover-timeout master1 900000sentinel parallel-syncs master1 1#sentinel auth-pass mymaster 123456 #如果你的redis集群有密码 配置文件的含义请自行百度。 启动哨兵三台机器都是一个操作方式。 添加窗口screen -S sentinel 在新窗口启动哨兵/opt/redis/src/redis-sentinel /opt/redis/conf/sentinel.conf –protected-mode no启动后即可看到前台输出信息。 后台挂起这个窗口请按：Ctrl+a+d 下次返回观看这个窗口请输入screen -r sentinel 我们这里暂时不挂起窗口，可以观察哨兵监控集群的状态。 我们接下来我们进行切换以及增加新的salve节点测试。关掉redis-1并查看哨兵监控的状态，约30秒内，哨兵探测redis-1客观故障后，即会重新选举新的master，重新选举完毕后我们在redis-2中info查看主从状态，会发现redis-2已经被选举为master。重新启动redis-1，并不需要修改配置文件，启动后redis-1自动会与redis-2进行同步。 修改redis-3的配置文件，把slaveof指向到redis-2，启动后你会发现哨兵会把redis-3自动添加到集群中。 原文：https://www.cnblogs.com/kerwinC/p/6069864.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo NexT主题中集成gitalk评论系统]]></title>
    <url>%2F2018%2F08%2F23%2Fhexo-gitalk%2F</url>
    <content type="text"><![CDATA[记录在NexT主题中添加gitalk评论系统的步骤。gitalk：一个基于 Github Issue 和 Preact 开发的评论插件详情Demo可见：https://gitalk.github.io/ Register Application在GitHub上注册新应用，链接：https://github.com/settings/applications/new参数说明：Application name： # 应用名称，随意Homepage URL： # 网站URL，如https://asdfv1929.github.ioApplication description # 描述，随意Authorization callback URL：# 网站URL，https://asdfv1929.github.io 点击注册后，页面跳转如下，其中Client ID和Client Secret在后面的配置中需要用到，到时复制粘贴即可： gitalk.swig新建/layout/_third-party/comments/gitalk.swig文件，并添加内容：12345678910111213141516&#123;% if page.comments &amp;&amp; theme.gitalk.enable %&#125; &lt;link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"&gt; &lt;script src="https://unpkg.com/gitalk/dist/gitalk.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; var gitalk = new Gitalk(&#123; clientID: '&#123;&#123; theme.gitalk.ClientID &#125;&#125;', clientSecret: '&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;', repo: '&#123;&#123; theme.gitalk.repo &#125;&#125;', owner: '&#123;&#123; theme.gitalk.githubID &#125;&#125;', admin: ['&#123;&#123; theme.gitalk.adminUser &#125;&#125;'], id: location.pathname, distractionFreeMode: '&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;' &#125;) gitalk.render('gitalk-container') &lt;/script&gt;&#123;% endif %&#125; comments.swig修改/layout/_partials/comments.swig，添加内容如下，与前面的elseif同一级别上：12&#123;% elseif theme.gitalk.enable %&#125; &lt;div id="gitalk-container"&gt;&lt;/div&gt; index.swig修改layout/_third-party/comments/index.swig，在最后一行添加内容：1&#123;% include 'gitalk.swig' %&#125; gitalk.styl新建/source/css/_common/components/third-party/gitalk.styl文件，添加内容：1234.gt-header a, .gt-comments a, .gt-popup a border-bottom: none;.gt-container .gt-popup .gt-action.is--active:before top: 0.7em; third-party.styl修改/source/css/_common/components/third-party/third-party.styl，在最后一行上添加内容，引入样式：1@import "gitalk"; _config.yml在主题配置文件next/_config.yml中添加如下内容：12345678gitalk: enable: true githubID: github帐号 # 例：asdfv1929 repo: 仓库名称 # 例：asdfv1929.github.io ClientID: Client ID ClientSecret: Client Secret adminUser: github帐号 #指定可初始化评论账户 distractionFreeMode: true 以上就是NexT中添加gitalk评论的配置，博客上传到GitHub上后，打开页面进入某一博客内容下，就可看到评论处。 部分问题解决方法，可参见：https://liujunzhou.cn/2018/8/10/gitalk-error/#more 原文：https://asdfv1929.github.io/2018/01/20/gitalk]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo添加右侧公众号]]></title>
    <url>%2F2018%2F08%2F23%2Fhexo-wechat-qrcode%2F</url>
    <content type="text"><![CDATA[hexo添加右侧公众号页面需在两处添加代码1、csscss添加在主题文件下的source/css/_schemes/主题名称文件夹/_layout123456789101112131415161718192021222324252627282930313233343536373839.paral&#123; position: absolute; top: 10%; right: 0; width:200px; height:140px; -webkit-user-select:none; ##禁止鼠标选中 -moz-user-select:none; -ms-user-select:none; user-select:none;&#125;.zi&#123; position: absolute; right: 0; width:30px; height:120px; writing-mode: vertical-lr; ##文字垂直 text-align:center; ##文字居中 background-color:#e2e5b7; font-size:18px; cursor:pointer; ##划过时鼠标样式 top:50%; transform:translateY(-50%); ##p标签垂直居中 border:1px solid #d1d8bd; border-radius:5px; ##边框圆角&#125;.img&#123; position: absolute; right: 60px; width: 140px; height: 140px; display: none; ##默认不显示图片&#125;p:hover +.img &#123; display: block; ##鼠标划过时，改变class--img属性为显示&#125; 2、HTMLHTML代码添加到主题文件夹下layout/_layout.swig中class为main中1234&lt;div class="paral"&gt; &lt;p class="zi"&gt;公众号&lt;/p&gt; &lt;img src="/uploads/qrcode_for_smartfoot.jpg" class="img"&gt;&lt;/div&gt;]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM大对象直接进入老年代]]></title>
    <url>%2F2018%2F08%2F20%2Fa8%2F</url>
    <content type="text"><![CDATA[原文：https://book.2cto.com/201306/25496.html 虚拟机提供了一个-XX:PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配。这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存复制（复习一下：新生代采用复制算法收集内存）。 所谓的大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串以及数组（笔者列出的例子中的byte[]数组就是典型的大对象）。大对象对虚拟机的内存分配来说就是一个坏消息（替Java虚拟机抱怨一句，比遇到一个大对象更加坏的消息就是遇到一群“朝生夕灭”的“短命大对象”，写程序的时候应当避免），经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们。 注意 PretenureSizeThreshold参数只对Serial和ParNew两款收集器有效，Parallel Scavenge收集器不认识这个参数，Parallel Scavenge收集器一般并不需要设置。如果遇到必须使用此参数的场合，可以考虑ParNew加CMS的收集器组合。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM出现频繁GC (Allocation Failure)及young gc时间过长分析]]></title>
    <url>%2F2018%2F08%2F20%2Fa7%2F</url>
    <content type="text"><![CDATA[序本文主要分析一个频繁GC (Allocation Failure)及young gc时间过长的case。 症状 gc throughput percent逐步下降，从一般的99.96%逐步下降，跌破99%，进入98%，最低点能到94% young gc time逐步增加，从一般的十几毫秒逐步上升，突破50，再突破100，150，200，250 在8.5天的时间内，发生了9000多次gc，其中full gc为4次，平均将近8秒，大部分是young gc(allocation failure为主)，平均270多毫秒，最大值将近7秒 平均对象创建速率为10.63 mb/sec，平均的晋升速率为2 kb/sec，cpu使用率正常，没有明显的飙升jvm参数https://my.oschina.net/go4it/blog/1628795]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM -XX:NewRatio、-XX:SurvivorRatio参数含义]]></title>
    <url>%2F2018%2F08%2F20%2Fa6%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高并发下载tomcat下的文件时,发生java.net.SocketException:Connection reset解决方案]]></title>
    <url>%2F2018%2F08%2F20%2Fa5%2F</url>
    <content type="text"><![CDATA[可能是服务器连接超过最大并发数而重置，导致客户端连接超时在tomcat的conf目录下，查看server.xml找到&lt;Connector port=”8080” 标签内添加，确认下当前的连接，可以做如下调整（具体需要根据实际情况设定）：12maxThreads="500" minSpareThreads="50" maxSpareThreads="100" enableLookups="false" acceptCount="500" 参考1、http://blog.sina.com.cn/s/blog_43eb83b90102ds8w.html2、http://www.cnblogs.com/qqzy168/archive/2012/09/04/2670002.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springmvc + mybatis 遍历Map]]></title>
    <url>%2F2018%2F08%2F20%2Fa4%2F</url>
    <content type="text"><![CDATA[spring的application.xml中数据源:12345678910111213&lt;!-- enterpriseUser数据库 --&gt;&lt;bean id="enterpriseUserDataSource" class="org.apache.commons.dbcp2.BasicDataSource"&gt; &lt;property name="driverClassName" value="$&#123;td.jdbc.enterpriseuser.driverClassName&#125;"/&gt; &lt;property name="url" value="$&#123;td.jdbc.enterpriseuser.url&#125;"/&gt; &lt;property name="username" value="$&#123;td.jdbc.enterpriseuser.username&#125;"/&gt; &lt;property name="password" value="$&#123;td.jdbc.enterpriseuser.password&#125;"/&gt; &lt;property name="initialSize" value="$&#123;td.jdbc.enterpriseuser.initialSize&#125;"/&gt; &lt;property name="maxTotal" value="$&#123;td.jdbc.enterpriseuser.maxActive&#125;"/&gt; &lt;property name="maxIdle" value="$&#123;td.jdbc.enterpriseuser.maxIdle&#125;"/&gt; &lt;property name="minIdle" value="$&#123;td.jdbc.enterpriseuser.minIdle&#125;"/&gt; &lt;property name="testOnBorrow" value="$&#123;td.jdbc.enterpriseuser.testOnBorrow&#125;"/&gt; &lt;property name="validationQuery" value="$&#123;td.jdbc.enterpriseuser.validationQuery&#125;"/&gt;&lt;/bean&gt; sessionFactory:12345678bean id="enterpriseSqlFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!-- 注入数据库连接池 --&gt; &lt;property name="dataSource" ref="enterpriseDataSource" /&gt; &lt;!-- 配置MyBaties全局配置文件:mybatis-config.xml --&gt; &lt;property name="configLocation" value="classpath:mybatis/mybatis-config.xml" /&gt; &lt;!-- 扫描sql配置文件:mapper需要的xml文件 --&gt; &lt;property name="mapperLocations" value="classpath:mybatis/enterprise_mapper/*.xml" /&gt;&lt;/bean&gt; Mapper.xml中的一个查询:123456789101112131415&lt;select id="queryBitmapIsolateParams" resultType="java.util.Map" parameterType="java.util.Map"&gt; &lt;!-- 具体的sql --&gt; $&#123;sql&#125; &lt;!-- 具体参数 --&gt; &lt;where&gt; &lt;if test="params != null"&gt; &lt;foreach collection="params.keys" item="key" separator="and"&gt; &lt;choose&gt; &lt;when test="#&#123;params[#&#123;key&#125;]&#125; == null"&gt; `$&#123;key&#125;` IS NULL &lt;/when&gt; &lt;otherwise&gt; `$&#123;key&#125;` = #&#123;params[$&#123;key&#125;]&#125; &lt;/otherwise&gt; &lt;/choose&gt; &lt;/foreach&gt; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt;]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>springmvc</tag>
        <tag>mybatis</tag>
        <tag>遍历</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven settings.xml详解]]></title>
    <url>%2F2018%2F08%2F15%2Fa3%2F</url>
    <content type="text"><![CDATA[setting.xml配置文件maven的配置文件settings.xml存在于两个地方： 1.安装的地方：${M2_HOME}/conf/settings.xml 2.用户的目录：${user.home}/.m2/settings.xml 前者又被叫做全局配置，对操作系统的所有使用者生效；后者被称为用户配置，只对当前操作系统的使用者生效。如果两者都存在，它们的内容将被合并，并且用户范围的settings.xml会覆盖全局的settings.xml。Maven安装后，用户目录下不会自动生成settings.xml，只有全局配置文件。如果需要创建用户范围的settings.xml，可以将安装路径下的settings复制到目录${user.home}/.m2/。Maven默认的settings.xml是一个包含了注释和例子的模板，可以快速的修改它来达到你的要求。 全局配置一旦更改，所有的用户都会受到影响，而且如果maven进行升级，所有的配置都会被清除，所以要提前复制和备份${M2_HOME}/conf/settings.xml文件，一般情况下不推荐配置全局的settings.xml。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;settings xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd"&gt; &lt;!--本地仓库。该值表示构建系统本地仓库的路径。其默认值为$&#123;user.home&#125;/.m2/repository。 --&gt; &lt;localRepository&gt;usr/local/maven&lt;/localRepository&gt; &lt;!--Maven是否需要和用户交互以获得输入。如果Maven需要和用户交互以获得输入，则设置成true，反之则应为false。默认为true。 --&gt; &lt;interactiveMode&gt;true&lt;/interactiveMode&gt; &lt;!--Maven是否需要使用plugin-registry.xml文件来管理插件版本。 --&gt; &lt;!--如果设置为true，则在&#123;user.home&#125;/.m2下需要有一个plugin-registry.xml来对plugin的版本进行管理 --&gt; &lt;!--默认为false。 --&gt; &lt;usePluginRegistry&gt;false&lt;/usePluginRegistry&gt; &lt;!--表示Maven是否需要在离线模式下运行。如果构建系统需要在离线模式下运行，则为true，默认为false。 --&gt; &lt;!--当由于网络设置原因或者安全因素，构建服务器不能连接远程仓库的时候，该配置就十分有用。 --&gt; &lt;offline&gt;false&lt;/offline&gt; &lt;!--当插件的组织Id（groupId）没有显式提供时，供搜寻插件组织Id（groupId）的列表。 --&gt; &lt;!--该元素包含一个pluginGroup元素列表，每个子元素包含了一个组织Id（groupId）。 --&gt; &lt;!--当我们使用某个插件，并且没有在命令行为其提供组织Id（groupId）的时候，Maven就会使用该列表。 --&gt; &lt;!--默认情况下该列表包含了org.apache.maven.plugins。 --&gt; &lt;pluginGroups&gt; &lt;!--plugin的组织Id（groupId） --&gt; &lt;pluginGroup&gt;org.codehaus.mojo&lt;/pluginGroup&gt; &lt;/pluginGroups&gt; &lt;!--用来配置不同的代理，多代理profiles可以应对笔记本或移动设备的工作环境：通过简单的设置profile id就可以很容易的更换整个代理配置。 --&gt; &lt;proxies&gt; &lt;!--代理元素包含配置代理时需要的信息 --&gt; &lt;proxy&gt; &lt;!--代理的唯一定义符，用来区分不同的代理元素。 --&gt; &lt;id&gt;myproxy&lt;/id&gt; &lt;!--该代理是否是激活的那个。true则激活代理。当我们声明了一组代理，而某个时候只需要激活一个代理的时候，该元素就可以派上用处。 --&gt; &lt;active&gt;true&lt;/active&gt; &lt;!--代理的协议。 协议://主机名:端口，分隔成离散的元素以方便配置。 --&gt; &lt;protocol&gt;http://…&lt;/protocol&gt; &lt;!--代理的主机名。协议://主机名:端口，分隔成离散的元素以方便配置。 --&gt; &lt;host&gt;proxy.somewhere.com&lt;/host&gt; &lt;!--代理的端口。协议://主机名:端口，分隔成离散的元素以方便配置。 --&gt; &lt;port&gt;8080&lt;/port&gt; &lt;!--代理的用户名，用户名和密码表示代理服务器认证的登录名和密码。 --&gt; &lt;username&gt;proxyuser&lt;/username&gt; &lt;!--代理的密码，用户名和密码表示代理服务器认证的登录名和密码。 --&gt; &lt;password&gt;somepassword&lt;/password&gt; &lt;!--不该被代理的主机名列表。该列表的分隔符由代理服务器指定；例子中使用了竖线分隔符，使用逗号分隔也很常见。 --&gt; &lt;nonProxyHosts&gt;*.google.com|ibiblio.org&lt;/nonProxyHosts&gt; &lt;/proxy&gt; &lt;/proxies&gt; &lt;!--配置服务端的一些设置。一些设置如安全证书不应该和pom.xml一起分发。这种类型的信息应该存在于构建服务器上的settings.xml文件中。 --&gt; &lt;servers&gt; &lt;!--服务器元素包含配置服务器时需要的信息 --&gt; &lt;server&gt; &lt;!--这是server的id（注意不是用户登陆的id），该id与distributionManagement中repository元素的id相匹配。 --&gt; &lt;id&gt;server001&lt;/id&gt; &lt;!--鉴权用户名。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。 --&gt; &lt;username&gt;my_login&lt;/username&gt; &lt;!--鉴权密码 。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。 --&gt; &lt;password&gt;my_password&lt;/password&gt; &lt;!--鉴权时使用的私钥位置。和前两个元素类似，私钥位置和私钥密码指定了一个私钥的路径（默认是/home/hudson/.ssh/id_dsa）以及如果需要的话，一个密钥 --&gt; &lt;!--将来passphrase和password元素可能会被提取到外部，但目前它们必须在settings.xml文件以纯文本的形式声明。 --&gt; &lt;privateKey&gt;$&#123;usr.home&#125;/.ssh/id_dsa&lt;/privateKey&gt; &lt;!--鉴权时使用的私钥密码。 --&gt; &lt;passphrase&gt;some_passphrase&lt;/passphrase&gt; &lt;!--文件被创建时的权限。如果在部署的时候会创建一个仓库文件或者目录，这时候就可以使用权限（permission）。--&gt; &lt;!--这两个元素合法的值是一个三位数字，其对应了unix文件系统的权限，如664，或者775。 --&gt; &lt;filePermissions&gt;664&lt;/filePermissions&gt; &lt;!--目录被创建时的权限。 --&gt; &lt;directoryPermissions&gt;775&lt;/directoryPermissions&gt; &lt;!--传输层额外的配置项 --&gt; &lt;configuration&gt;&lt;/configuration&gt; &lt;/server&gt; &lt;/servers&gt; &lt;!--为仓库列表配置的下载镜像列表。 --&gt; &lt;mirrors&gt; &lt;!--给定仓库的下载镜像。 --&gt; &lt;mirror&gt; &lt;!--该镜像的唯一标识符。id用来区分不同的mirror元素。 --&gt; &lt;id&gt;planetmirror.com&lt;/id&gt; &lt;!--镜像名称 --&gt; &lt;name&gt;PlanetMirror Australia&lt;/name&gt; &lt;!--该镜像的URL。构建系统会优先考虑使用该URL，而非使用默认的服务器URL。 --&gt; &lt;url&gt;http://downloads.planetmirror.com/pub/maven2&lt;/url&gt; &lt;!--被镜像的服务器的id。例如，如果我们要设置了一个Maven中央仓库（http://repo1.maven.org/maven2）的镜像，--&gt; &lt;!--就需要将该元素设置成central。这必须和中央仓库的id central完全一致。 --&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;!--根据环境参数来调整构建配置的列表。settings.xml中的profile元素是pom.xml中profile元素的裁剪版本。--&gt; &lt;!--它包含了id，activation, repositories, pluginRepositories和 properties元素。--&gt; &lt;!--这里的profile元素只包含这五个子元素是因为这里只关心构建系统这个整体（这正是settings.xml文件的角色定位），而非单独的项目对象模型设置。--&gt; &lt;!--如果一个settings中的profile被激活，它的值会覆盖任何其它定义在POM中或者profile.xml中的带有相同id的profile。 --&gt; &lt;profiles&gt; &lt;!--根据环境参数来调整的构件的配置 --&gt; &lt;profile&gt; &lt;!--该配置的唯一标识符。 --&gt; &lt;id&gt;test&lt;/id&gt; &lt;!--自动触发profile的条件逻辑。Activation是profile的开启钥匙。--&gt; &lt;!--如POM中的profile一样，profile的力量来自于它能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。--&gt; &lt;!--activation元素并不是激活profile的唯一方式。settings.xml文件中的activeProfile元素可以包含profile的id。--&gt; &lt;!--profile也可以通过在命令行，使用-P标记和逗号分隔的列表来显式的激活（如，-P test）。 --&gt; &lt;activation&gt; &lt;!--profile默认是否激活的标识 --&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;!--activation有一个内建的java版本检测，如果检测到jdk版本与期待的一样，profile被激活。 --&gt; &lt;jdk&gt;1.7&lt;/jdk&gt; &lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。 --&gt; &lt;os&gt; &lt;!--激活profile的操作系统的名字 --&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;!--激活profile的操作系统所属家族(如 'windows') --&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;!--激活profile的操作系统体系结构 --&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;!--激活profile的操作系统版本 --&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;!--如果Maven检测到某一个属性（其值可以在POM中通过$&#123;名称&#125;引用），其拥有对应的名称和值，Profile就会被激活。--&gt; &lt;!--如果值字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段 --&gt; &lt;property&gt; &lt;!--激活profile的属性的名称 --&gt; &lt;name&gt;mavenVersion&lt;/name&gt; &lt;!--激活profile的属性的值 --&gt; &lt;value&gt;2.0.3&lt;/value&gt; &lt;/property&gt; &lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活profile。--&gt; &lt;!--另一方面，exists则会检查文件是否存在，如果存在则激活profile。 --&gt; &lt;file&gt; &lt;!--如果指定的文件存在，则激活profile。 --&gt; &lt;exists&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/exists&gt; &lt;!--如果指定的文件不存在，则激活profile。 --&gt; &lt;missing&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; &lt;!--对应profile的扩展属性列表。Maven属性和Ant中的属性一样，可以用来存放一些值。这些值可以在POM中的任何地方使用标记$&#123;X&#125;来使用，这里X是指属性的名称。--&gt; &lt;!--属性有五种不同的形式，并且都能在settings.xml文件中访问。 --&gt; &lt;!--1. env.X: 在一个变量前加上"env."的前缀，会返回一个shell环境变量。例如,"env.PATH"指代了$path环境变量（在Windows上是%PATH%）。 --&gt; &lt;!--2. project.x：指代了POM中对应的元素值。 --&gt; &lt;!--3. settings.x: 指代了settings.xml中对应元素的值。 --&gt; &lt;!--4. Java System Properties: 所有可通过java.lang.System.getProperties()访问的属性都能在POM中使用该形式访问， --&gt; &lt;!-- 如/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0/jre。 --&gt; &lt;!--5. x: 在&lt;properties/&gt;元素中，或者外部文件中设置，以$&#123;someVar&#125;的形式使用。 --&gt; &lt;properties&gt; &lt;!-- 如果这个profile被激活，那么属性$&#123;user.install&#125;就可以被访问了 --&gt; &lt;user.install&gt;usr/local/winner/jobs/maven-guide&lt;/user.install&gt; &lt;/properties&gt; &lt;!--远程仓库列表，它是Maven用来填充构建系统本地仓库所使用的一组远程项目。 --&gt; &lt;repositories&gt; &lt;!--包含需要连接到远程仓库的信息 --&gt; &lt;repository&gt; &lt;!--远程仓库唯一标识 --&gt; &lt;id&gt;codehausSnapshots&lt;/id&gt; &lt;!--远程仓库名称 --&gt; &lt;name&gt;Codehaus Snapshots&lt;/name&gt; &lt;!--如何处理远程仓库里发布版本的下载 --&gt; &lt;releases&gt; &lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：--&gt; &lt;!--always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;!--当Maven验证构件校验文件失败时该怎么做:--&gt; &lt;!--ignore（忽略），fail（失败），或者warn（警告）。 --&gt; &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt; &lt;/releases&gt; &lt;!--如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的策略。--&gt; &lt;!--例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --&gt; &lt;snapshots&gt; &lt;enabled /&gt; &lt;updatePolicy /&gt; &lt;checksumPolicy /&gt; &lt;/snapshots&gt; &lt;!--远程仓库URL，按protocol://hostname/path形式 --&gt; &lt;url&gt;http://snapshots.maven.codehaus.org/maven2&lt;/url&gt; &lt;!--用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。--&gt; &lt;!--Maven 2为其仓库提供了一个默认的布局；然而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!--发现插件的远程仓库列表。仓库是两种主要构件的家。第一种构件被用作其它构件的依赖。这是中央仓库中存储的大部分构件类型。另外一种构件类型是插件。--&gt; &lt;!--Maven插件是一种特殊类型的构件。由于这个原因，插件仓库独立于其它仓库。pluginRepositories元素的结构和repositories元素的结构类似。--&gt; &lt;!--每个pluginRepository元素指定一个Maven可以用来寻找新插件的远程地址。 --&gt; &lt;pluginRepositories&gt; &lt;!--包含需要连接到远程插件仓库的信息.参见profiles/profile/repositories/repository元素的说明 --&gt; &lt;pluginRepository&gt; &lt;releases&gt; &lt;enabled /&gt; &lt;updatePolicy /&gt; &lt;checksumPolicy /&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled /&gt; &lt;updatePolicy /&gt; &lt;checksumPolicy /&gt; &lt;/snapshots&gt; &lt;id /&gt; &lt;name /&gt; &lt;url /&gt; &lt;layout /&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!--手动激活profiles的列表，按照profile被应用的顺序定义activeProfile。 该元素包含了一组activeProfile元素，每个activeProfile都含有一个profile id。--&gt; &lt;!--任何在activeProfile中定义的profile id，不论环境设置如何，其对应的 profile都会被激活。--&gt; &lt;!--如果没有匹配的profile，则什么都不会发生。例如，env-test是一个activeProfile，则在pom.xml（或者profile.xml）中对应id的profile会被激活。--&gt; &lt;!--如果运行过程中找不到这样一个profile，Maven则会像往常一样运行。 --&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;env-test&lt;/activeProfile&gt; &lt;/activeProfiles&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;/settings&gt; 上面的配置文件对各个节点的含义及作用都有注解。实际应用中，经常使用的是、、、有限几个节点，其他节点使用默认值足够应对大部分的应用场景。 节点在仓库的配置一节中，已经对setting.xml中的常用节点做了详细的说明。在这里需要特别介绍一下的是节点的配置，profile是maven的一个重要特性。 节点包含了激活(activation)，仓库(repositories)，插件仓库(pluginRepositories)和属性(properties)共四个子元素元素。profile元素仅包含这四个元素是因为他们涉及到整个的构建系统，而不是个别的项目级别的POM配置。 profile可以让maven能够自动适应外部的环境变化，比如同一个项目，在linux下编译linux的版本，在win下编译win的版本等。一个项目可以设置多个profile，也可以在同一时间设置多个profile被激活（active）的。自动激活的 profile的条件可以是各种各样的设定条件，组合放置在activation节点中，也可以通过命令行直接指定。如果认为profile设置比较复杂，可以将所有的profiles内容移动到专门的 profiles.xml 文件中，不过记得和pom.xml放在一起。 activation节点是设置该profile在什么条件下会被激活，常见的条件有如下几个： os 判断操作系统相关的参数，它包含如下可以自由组合的子节点元素 message - 规则失败之后显示的消息 arch - 匹配cpu结构，常见为x86 family - 匹配操作系统家族，常见的取值为：dos，mac，netware，os/2，unix，windows，win9x，os/400等 name - 匹配操作系统的名字 version - 匹配的操作系统版本号 display - 检测到操作系统之后显示的信息 jdk 检查jdk版本，可以用区间表示。 property 检查属性值，本节点可以包含name和value两个子节点。 file 检查文件相关内容，包含两个子节点：exists和missing，用于分别检查文件存在和不存在两种情况。 如果settings中的profile被激活，那么它的值将覆盖POM或者profiles.xml中的任何相等ID的profiles。 如果想要某个profile默认处于激活状态，可以在中将该profile的id放进去。这样，不论环境设置如何，其对应的 profile都会被激活。 原文出处：http://blog.csdn.net/u012152619/article/details/51485152]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM初探- 内存分配、GC原理与垃圾收集器]]></title>
    <url>%2F2018%2F08%2F15%2Fa2%2F</url>
    <content type="text"><![CDATA[JVM内存的分配与回收大致可分为如下4个步骤: 何时分配 -&gt; 怎样分配 -&gt; 何时回收 -&gt; 怎样回收. 除了在概念上可简单认为new时分配外, 我们着重介绍后面的3个步骤: I. 怎样分配- JVM内存分配策略对象内存主要分配在新生代Eden区, 如果启用了本地线程分配缓冲, 则优先在TLAB上分配, 少数情况能会直接分配在老年代, 或被拆分成标量类型在栈上分配(JIT优化). 分配的规则并不是百分百固定, 细节主要取决于垃圾收集器组合, 以及VM内存相关的参数. 对象分配 优先在Eden区分配在JVM内存模型一文中, 我们大致了解了VM年轻代堆内存可以划分为一块Eden区和两块Survivor区. 在大多数情况下, 对象在新生代Eden区中分配, 当Eden区没有足够空间分配时, VM发起一次Minor GC, 将Eden区和其中一块Survivor区内尚存活的对象放入另一块Survivor区域, 如果在Minor GC期间发现新生代存活对象无法放入空闲的Survivor区, 则会通过空间分配担保机制使对象提前进入老年代(空间分配担保见下). 大对象直接进入老年代Serial和ParNew两款收集器提供了-XX:PretenureSizeThreshold的参数, 令大于该值的大对象直接在老年代分配, 这样做的目的是避免在Eden区和Survivor区之间产生大量的内存复制(大对象一般指 需要大量连续内存的Java对象, 如很长的字符串和数组), 因此大对象容易导致还有不少空闲内存就提前触发GC以获取足够的连续空间. 对象晋升 年龄阈值VM为每个对象定义了一个对象年龄(Age)计数器, 对象在Eden出生如果经第一次Minor GC后仍然存活, 且能被Survivor容纳的话, 将被移动到Survivor空间中, 并将年龄设为1. 以后对象在Survivor区中每熬过一次Minor GC年龄就+1. 当增加到一定程度(-XX:MaxTenuringThreshold, 默认15), 将会晋升到老年代. 提前晋升: 动态年龄判定然而VM并不总是要求对象的年龄必须达到MaxTenuringThreshold才能晋升老年代: 如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半, 年龄大于或等于该年龄的对象就可以直接进入老年代, 而无须等到晋升年龄. II. 何时回收-对象生死判定(哪些内存需要回收/何时回收) 在堆里面存放着Java世界中几乎所有的对象实例, 垃圾收集器在对堆进行回收前, 第一件事就是判断哪些对象已死(可回收). 可达性分析算法在主流商用语言(如Java、C#)的主流实现中, 都是通过可达性分析算法来判定对象是否存活的: 通过一系列的称为 GC Roots 的对象作为起点, 然后向下搜索; 搜索所走过的路径称为引用链/Reference Chain, 当一个对象到 GC Roots 没有任何引用链相连时, 即该对象不可达, 也就说明此对象是不可用的, 如下图: Object5、6、7 虽然互有关联, 但它们到GC Roots是不可达的, 因此也会被判定为可回收的对象: 在Java, 可作为GC Roots的对象包括: 方法区: 类静态属性引用的对象; 方法区: 常量引用的对象; 虚拟机栈(本地变量表)中引用的对象. 本地方法栈JNI(Native方法)中引用的对象。 注: 即使在可达性分析算法中不可达的对象, VM也并不是马上对其回收, 因为要真正宣告一个对象死亡, 至少要经历两次标记过程: 第一次是在可达性分析后发现没有与GC Roots相连接的引用链, 第二次是GC对在F-Queue执行队列中的对象进行的小规模标记(对象需要覆盖finalize()方法且没被调用过). III. GC原理- 垃圾收集算法分代收集算法 VS 分区收集算法 分代收集当前主流VM垃圾收集都采用”分代收集”(Generational Collection)算法, 这种算法会根据对象存活周期的不同将内存划分为几块, 如JVM中的 新生代、老年代、永久代. 这样就可以根据各年代特点分别采用最适当的GC算法: 在新生代: 每次垃圾收集都能发现大批对象已死, 只有少量存活. 因此选用复制算法, 只需要付出少量存活对象的复制成本就可以完成收集. 在老年代: 因为对象存活率高、没有额外空间对它进行分配担保, 就必须采用“标记—清理”或“标记—整理”算法来进行回收, 不必进行内存复制, 且直接腾出空闲内存. 分区收集上面介绍的分代收集算法是将对象的生命周期按长短划分为两个部分, 而分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的好处是可以控制一次回收多少个小区间.在相同条件下, 堆空间越大, 一次GC耗时就越长, 从而产生的停顿也越长. 为了更好地控制GC产生的停顿时间, 将一块大的内存区域分割为多个小块, 根据目标停顿时间, 每次合理地回收若干个小区间(而不是整个堆), 从而减少一次GC所产生的停顿. 分代收集新生代-复制算法该算法的核心是将可用内存按容量划分为大小相等的两块, 每次只用其中一块, 当这一块的内存用完, 就将还存活的对象复制到另外一块上面, 然后把已使用过的内存空间一次清理掉. (图片来源: jvm垃圾收集算)这使得每次只对其中一块内存进行回收, 分配也就不用考虑内存碎片等复杂情况, 实现简单且运行高效. 现代商用VM的新生代均采用复制算法, 但由于新生代中的98%的对象都是生存周期极短的, 因此并不需完全按照1∶1的比例划分新生代空间, 而是将新生代划分为一块较大的Eden区和两块较小的Survivor区(HotSpot默认Eden和Survivor的大小比例为8∶1), 每次只用Eden和其中一块Survivor. 当发生MinorGC时, 将Eden和Survivor中还存活着的对象一次性地拷贝到另外一块Survivor上, 最后清理掉Eden和刚才用过的Survivor的空间. 当Survivor空间不够用(不足以保存尚存活的对象)时, 需要依赖老年代进行空间分配担保机制, 这部分内存直接进入老年代. 老年代-标记清除算法该算法分为“标记”和“清除”两个阶段: 首先标记出所有需要回收的对象(可达性分析), 在标记完成后统一清理掉所有被标记的对象. 该算法会有以下两个问题: 效率问题: 标记和清除过程的效率都不高; 空间问题: 标记清除后会产生大量不连续的内存碎片, 空间碎片太多可能会导致在运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集. 老年代-标记整理算法标记清除算法会产生内存碎片问题, 而复制算法需要有额外的内存担保空间, 于是针对老年代的特点, 又有了标记整理算法. 标记整理算法的标记过程与标记清除算法相同, 但后续步骤不再对可回收对象直接清理, 而是让所有存活的对象都向一端移动,然后清理掉端边界以外的内存. 永久代-方法区回收 在方法区进行垃圾回收一般”性价比”较低, 因为在方法区主要回收两部分内容: 废弃常量和无用的类. 回收废弃常量与回收其他年代中的对象类似, 但要判断一个类是否无用则条件相当苛刻: 该类所有的实例都已经被回收, Java堆中不存在该类的任何实例; 该类对应的Class对象没有在任何地方被引用(也就是在任何地方都无法通过反射访问该类的方法); 加载该类的ClassLoader已经被回收.但即使满足以上条件也未必一定会回收, Hotspot VM还提供了-Xnoclassgc参数控制(关闭CLASS的垃圾回收功能). 因此在大量使用动态代理、CGLib等字节码框架的应用中一定要关闭该选项, 开启VM的类卸载功能, 以保证方法区不会溢出. 补充: 空间分配担保在执行Minor GC前, VM会首先检查老年代是否有足够的空间存放新生代尚存活对象, 由于新生代使用复制收集算法, 为了提升内存利用率, 只使用了其中一个Survivor作为轮换备份, 因此当出现大量对象在Minor GC后仍然存活的情况时, 就需要老年代进行分配担保, 让Survivor无法容纳的对象直接进入老年代, 但前提是老年代需要有足够的空间容纳这些存活对象. 但存活对象的大小在实际完成GC前是无法明确知道的, 因此Minor GC前, VM会先首先检查老年代连续空间是否大于新生代对象总大小或历次晋升的平均大小, 如果条件成立, 则进行Minor GC, 否则进行Full GC(让老年代腾出更多空间).然而取历次晋升的对象的平均大小也是有一定风险的, 如果某次Minor GC存活后的对象突增,远远高于平均值的话,依然可能导致担保失败(Handle Promotion Failure, 老年代也无法存放这些对象了), 此时就只好在失败后重新发起一次Full GC(让老年代腾出更多空间). IX. GC实现- 垃圾收集器 GC实现目标: 准确、高效、低停顿、空闲内存规整. 新生代1. Serial收集器Serial收集器是Hotspot运行在Client模式下的默认新生代收集器, 它的特点是 只用一个CPU/一条收集线程去完成GC工作, 且在进行垃圾收集时必须暂停其他所有的工作线程(“Stop The World” -后面简称STW). 虽然是单线程收集, 但它却简单而高效, 在VM管理内存不大的情况下(收集几十M~一两百M的新生代), 停顿时间完全可以控制在几十毫秒~一百多毫秒内. 2. ParNew收集器ParNew收集器其实是前面Serial的多线程版本, 除使用多条线程进行GC外, 包括Serial可用的所有控制参数、收集算法、STW、对象分配规则、回收策略等都与Serial完全一样(也是VM启用CMS收集器-XX: +UseConcMarkSweepGC的默认新生代收集器). 由于存在线程切换的开销, ParNew在单CPU的环境中比不上Serial, 且在通过超线程技术实现的两个CPU的环境中也不能100%保证能超越Serial. 但随着可用的CPU数量的增加, 收集效率肯定也会大大增加(ParNew收集线程数与CPU的数量相同, 因此在CPU数量过大的环境中, 可用-XX:ParallelGCThreads参数控制GC线程数). 3. Parallel Scavenge收集器与ParNew类似, Parallel Scavenge也是使用复制算法, 也是并行多线程收集器. 但与其他收集器关注尽可能缩短垃圾收集时间不同, Parallel Scavenge更关注系统吞吐量:系统吞吐量=运行用户代码时间(运行用户代码时间+垃圾收集时间)停顿时间越短就越适用于用户交互的程序-良好的响应速度能提升用户的体验;而高吞吐量则适用于后台运算而不需要太多交互的任务-可以最高效率地利用CPU时间,尽快地完成程序的运算任务. Parallel Scavenge提供了如下参数设置系统吞吐量: Parallel Scavenge参数 描述 MaxGCPauseMillis (毫秒数) 收集器将尽力保证内存回收花费的时间不超过设定值, 但如果太小将会导致GC的频率增加. GCTimeRatio (整数:0 &lt; GCTimeRatio &lt; 100) 是垃圾收集时间占总时间的比率 -XX:+UseAdaptiveSizePolicy 启用GC自适应的调节策略: 不再需要手工指定-Xmn、-XX:SurvivorRatio、-XX:PretenureSizeThreshold等细节参数, VM会根据当前系统的运行情况收集性能监控信息, 动态调整这些参数以提供最合适的停顿时间或最大的吞吐量 老年代Serial Old收集器Serial Old是Serial收集器的老年代版本, 同样是单线程收集器,使用“标记-整理”算法: Serial Old应用场景如下: JDK 1.5之前与Parallel Scavenge收集器搭配使用; 作为CMS收集器的后备预案, 在并发收集发生Concurrent Mode Failure时启用(见下:CMS收集器). Parallel Old收集器Parallel Old是Parallel Scavenge收老年代版本, 使用多线程和“标记－整理”算法, 吞吐量优先, 主要与Parallel Scavenge配合在 注重吞吐量 及 CPU资源敏感 系统内使用: CMS收集器CMS(Concurrent Mark Sweep)收集器是一款具有划时代意义的收集器, 一款真正意义上的并发收集器, 虽然现在已经有了理论意义上表现更好的G1收集器, 但现在主流互联网企业线上选用的仍是CMS(如Taobao、微店).CMS是一种以获取最短回收停顿时间为目标的收集器(CMS又称多并发低暂停的收集器), 基于”标记-清除”算法实现, 整个GC过程分为以下4个步骤: 初始标记(CMS initial mark) 并发标记(CMS concurrent mark: GC Roots Tracing过程) 重新标记(CMS remark) 并发清除(CMS concurrent sweep: 已死象将会就地释放, 注意: 此处没有压缩) 其中两个加粗的步骤(初始标记、重新标记)仍需STW. 但初始标记仅只标记一下GC Roots能直接关联到的对象, 速度很快; 而重新标记则是为了修正并发标记期间因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录, 虽然一般比初始标记阶段稍长, 但要远小于并发标记时间. (由于整个GC过程耗时最长的并发标记和并发清除阶段的GC线程可与用户线程一起工作, 所以总体上CMS的GC过程是与用户线程一起并发地执行的.由于CMS收集器将整个GC过程进行了更细粒度的划分, 因此可以实现并发收集、低停顿的优势, 但它也并非十分完美, 其存在缺点及解决策略如下: CMS默认启动的回收线程数=(CPU数目+3)/4当CPU数&gt;4时, GC线程最多占用不超过25%的CPU资源, 但是当CPU数&lt;=4时, GC线程可能就会过多的占用用户CPU资源, 从而导致应用程序变慢, 总吞吐量降低. 无法处理浮动垃圾, 可能出现Promotion Failure、Concurrent Mode Failure而导致另一次Full GC的产生: 浮动垃圾是指在CMS并发清理阶段用户线程运行而产生的新垃圾. 由于在GC阶段用户线程还需运行, 因此还需要预留足够的内存空间给用户线程使用, 导致CMS不能像其他收集器那样等到老年代几乎填满了再进行收集. 因此CMS提供了-XX:CMSInitiatingOccupancyFraction参数来设置GC的触发百分比(以及-XX:+UseCMSInitiatingOccupancyOnly来启用该触发百分比), 当老年代的使用空间超过该比例后CMS就会被触发(JDK 1.6之后默认92%). 但当CMS运行期间预留的内存无法满足程序需要, 就会出现上述Promotion Failure等失败, 这时VM将启动后备预案: 临时启用Serial Old收集器来重新执行Full GC(CMS通常配合大内存使用, 一旦大内存转入串行的Serial GC, 那停顿的时间就是大家都不愿看到的了). 最后, 由于CMS采用”标记-清除”算法实现, 可能会产生大量内存碎片. 内存碎片过多可能会导致无法分配大对象而提前触发Full GC. 因此CMS提供了-XX:+UseCMSCompactAtFullCollection开关参数, 用于在Full GC后再执行一个碎片整理过程. 但内存整理是无法并发的, 内存碎片问题虽然没有了, 但停顿时间也因此变长了, 因此CMS还提供了另外一个参数-XX:CMSFullGCsBeforeCompaction用于设置在执行N次不进行内存整理的Full GC后, 跟着来一次带整理的(默认为0: 每次进入Full GC时都进行碎片整理). 分区收集- G1收集器 G1(Garbage-First)是一款面向服务端应用的收集器, 主要目标用于配备多颗CPU的服务器治理大内存. G1 is planned as the long term replacement for the Concurrent Mark-Sweep Collector (CMS). -XX:+UseG1GC 启用G1收集器. 与其他基于分代的收集器不同, G1将整个Java堆划分为多个大小相等的独立区域(Region), 虽然还保留有新生代和老年代的概念, 但新生代和老年代不再是物理隔离的了, 它们都是一部分Region(不需要连续)的集合. 每块区域既有可能属于O区、也有可能是Y区, 因此不需要一次就对整个老年代/新生代回收. 而是当线程并发寻找可回收的对象时, 有些区块包含可回收的对象要比其他区块多很多. 虽然在清理这些区块时G1仍然需要暂停应用线程, 但可以用相对较少的时间优先回收垃圾较多的Region(这也是G1命名的来源). 这种方式保证了G1可以在有限的时间内获取尽可能高的收集效率. 新生代收集G1的新生代收集跟ParNew类似: 存活的对象被转移到一个/多个Survivor Regions. 如果存活时间达到阀值, 这部分对象就会被提升到老年代. G1的新生代收集特点如下: 一整块堆内存被分为多个Regions. 存活对象被拷贝到新的Survivor区或老年代. 年轻代内存由一组不连续的heap区组成, 这种方法使得可以动态调整各代区域尺寸. Young GCs会有STW事件, 进行时所有应用程序线程都会被暂停. 多线程并发GC. 老年代收集G1老年代GC会执行以下阶段: 注: 一下有些阶段也是年轻代垃圾收集的一部分. index Phase Description (1) 初始标记 (Initial Mark: Stop the World Event) 在G1中, 该操作附着一次年轻代GC, 以标记Survivor中有可能引用到老年代对象的Regions. (2) 扫描根区域 (Root Region Scanning: 与应用程序并发执行) 扫描Survivor中能够引用到老年代的references. 但必须在Minor GC触发前执行完. (3) 并发标记 (Concurrent Marking : 与应用程序并发执行) 在整个堆中查找存活对象, 但该阶段可能会被Minor GC中断. (4) 重新标记 (Remark : Stop the World Event) 完成堆内存中存活对象的标记. 使用snapshot-at-the-beginning(SATB, 起始快照)算法, 比CMS所用算法要快得多(空Region直接被移除并回收, 并计算所有区域的活跃度). (5) 清理 (Cleanup : Stop the World Event and Concurrent) 见下 5-1、2、3 5-1 (Stop the world) 在含有存活对象和完全空闲的区域上进行统计 5-2 (Stop the world) 擦除Remembered Sets. 5-3 (Concurrent) 重置空regions并将他们返还给空闲列表(free list) (*) Copying/Cleanup (Stop the World Event) 选择”活跃度”最低的区域(这些区域可以最快的完成回收). 拷贝/转移存活的对象到新的尚未使用的regions. 该阶段会被记录在gc-log内(只发生年轻代[GC pause (young)], 与老年代一起执行则被记录为[GC Pause (mixed)]. 详细步骤可参考 Oracle官方文档-The G1 Garbage Collector Step by Step. G1老年代GC特点如下: 并发标记阶段(index 3) 在与应用程序并发执行的过程中会计算活跃度信息. 这些活跃度信息标识出那些regions最适合在STW期间回收(which regions will be best to reclaim during an evacuation pause). 不像CMS有清理阶段. 再次标记阶段(index 4) 使用Snapshot-at-the-Beginning(SATB)算法比CMS快得多. 空region直接被回收. 拷贝/清理阶段(Copying/Cleanup Phase) 年轻代与老年代同时回收. 老年代内存回收会基于他的活跃度信息. 补充: 关于Remembered SetG1收集器中, Region之间的对象引用以及其他收集器中的新生代和老年代之间的对象引用都是使用Remembered Set来避免扫描全堆. G1中每个Region都有一个与之对应的Remembered Set, VM发现程序对Reference类型数据进行写操作时, 会产生一个Write Barrier暂时中断写操作, 检查Reference引用的对象是否处于不同的Region中(在分代例子中就是检查是否老年代中的对象引用了新生代的对象), 如果是, 便通过CardTable把相关引用信息记录到被引用对象所属的Region的Remembered Set中. 当内存回收时, 在GC根节点的枚举范围加入Remembered Set即可保证不对全局堆扫描也不会有遗漏. V. JVM小工具在${JAVA_HOME}/bin/目录下Sun/Oracle给我们提供了一些处理应用程序性能问题、定位故障的工具, 包含 bin 描述 功能 jps 打印Hotspot VM进程 VMID、JVM参数、main()函数参数、主类名/Jar路径 jstat 查看Hotspot VM 运行时信息 类加载、内存、GC[可分代查看]、JIT编译 jinfo 查看和修改虚拟机各项配置 -flag name=value jmap heapdump: 生成VM堆转储快照、查询finalize执行队列、Java堆和永久代详细信息 jmap -dump:live,format=b,file=heap.bin [VMID] jstack 查看VM当前时刻的线程快照: 当前VM内每一条线程正在执行的方法堆栈集合 Thread.getAllStackTraces()提供了类似的功能 javap 查看经javac之后产生的JVM字节码代码 自动解析.class文件, 避免了去理解class文件格式以及手动解析class文件内容 jcmd 一个多功能工具, 可以用来导出堆, 查看Java进程、导出线程信息、 执行GC、查看性能相关数据等 几乎集合了jps、jstat、jinfo、jmap、jstack所有功能 jconsole 基于JMX的可视化监视、管理工具 可以查看内存、线程、类、CPU信息, 以及对JMX MBean进行管理 jvisualvm JDK中最强大运行监视和故障处理工具 可以监控内存泄露、跟踪垃圾回收、执行时内存分析、CPU分析、线程分析… VI. VM常用参数整理 参数 描述 -Xms 最小堆大小 -Xmx 最大堆大小 -Xmn 新生代大小 -XX:PermSize 永久代大小 -XX:MaxPermSize 永久代最大大小 -XX:+PrintGC 输出GC日志 -verbose:gc - -XX:+PrintGCDetails 输出GC的详细日志 -XX:+PrintGCTimeStamps 输出GC时间戳(以基准时间的形式) -XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息 -Xloggc:/path/gc.log 日志文件的输出路径 -XX:+PrintGCApplicationStoppedTime 打印由GC产生的停顿时间 在此处无法列举所有的参数以及他们的应用场景, 详细移步Oracle官方文档-Java HotSpot VM Options. 参考 &amp; 扩展深入理解Java虚拟机JVM内幕：Java虚拟机详解 (力荐)JVM中的G1垃圾回收器G1垃圾收集器入门Getting Started with the G1 Garbage Collector深入理解G1垃圾收集器解析JDK 7的Garbage-First收集器The Garbage-First Garbage CollectorMemory Management in the Java HotSpot Virtual MachineJava HotSpot VM OptionsJVM实用参数（一）JVM类型以及编译器模式JVM内存回收理论与实现基于OpenJDK深度定制的淘宝JVM（TaobaoVM） 原文出处： JVM初探- 内存分配、GC原理与垃圾收集器]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统平均负载指标解读]]></title>
    <url>%2F2018%2F08%2F13%2Fa1%2F</url>
    <content type="text"><![CDATA[一.使用top命令,看到右上角有个平均负载指标12345678top - 11:47:03 up 356 days, 20:33, 8 users, load average: 10.08, 11.02, 12.23Tasks: 159 total, 3 running, 156 sleeping, 0 stopped, 0 zombie%Cpu0 : 55.8 us, 11.5 sy, 0.0 ni, 17.3 id, 0.0 wa, 0.0 hi, 15.4 si, 0.0 st%Cpu1 : 36.7 us, 16.3 sy, 0.0 ni, 46.9 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 37.3 us, 15.7 sy, 0.0 ni, 47.1 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 30.8 us, 11.5 sy, 0.0 ni, 57.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 16268500 total, 169076 free, 8331188 used, 7768236 buff/cacheKiB Swap: 0 total, 0 free, 0 used. 7399704 avail Mem 当前cpu为4核逻辑处理器,如上所示,怎么判断当前系统是否超载?参考:https://blog.csdn.net/chenxiao_ji/article/details/46897695在Linux shell下，有很多命令可以看到Load Average，例如：12root@Slyar.com:~# uptime12:49:10 up 182 days, 16:54, 2 users, load average: 0.08, 0.04, 0.01 12root@Slyar.com:~# toptop - 12:50:28 up 182 days, 16:55, 2 users, load average: 0.02, 0.05, 0.00 先大致给一下这3个数字的含义：分别表示系统在过去1分钟、5分钟、15分钟内运行进程队列中的平均进程数量。运行队列嘛，没有等待IO，没有WAIT，没有KILL的进程通通都进这个队列。另外还有一个最直接的显示系统平均负载的命令12[172.23.6.189:hadoop@sz-pg-smce-cce-016:/home/hadoop]$ cat /proc/loadavg 12.04 11.32 12.15 26/664 6142 除了前3个数字表示平均进程数量外，后面的1个分数，分母表示系统进程总数，分子表示正在运行的进程数；最后一个数字表示最近运行的进程ID. 二.系统平均负载-进阶解释只是上面那一句话的解释，基本等于没解释。写这篇文章的缘由就是因为看到了一篇老外写的关于Load Average的文章，觉得解释的很好，所以才打算摘取一部分用自己的话翻译一下。@scoutapp Thanks for your article Understanding Linux CPU Load, I just translate and share it to Chinese audiences. 为了更好地理解系统负载，我们用交通流量来做类比。1、单核CPU - 单车道 - 数字在0.00-1.00之间正常路况管理员会告知司机，如果前面比较拥堵，那司机就要等待，如果前面一路畅通，那么司机就可以驾车直接开过。具体来说：0.00-1.00 之间的数字表示此时路况非常良好，没有拥堵，车辆可以毫无阻碍地通过。1.00 表示道路还算正常，但有可能会恶化并造成拥堵。此时系统已经没有多余的资源了，管理员需要进行优化。1.00-*** 表示路况不太好了，如果到达2.00表示有桥上车辆一倍数目的车辆正在等待。这种情况你必须进行检查了。到这里,可以判断,单核CPU处理时,平均负载数超过&gt;=2(一般看近5分钟,中间数值),即CPU出现超载 2、多核CPU - 多车道 - 数字/CPU核数 在0.00-1.00之间正常多核CPU的话，满负荷状态的数字为 “1.00 * CPU核数”，即双核CPU为2.00，四核CPU为4.00。 3、安全的系统平均负载作者认为单核负载在0.7以下是安全的，超过0.7就需要进行优化了。 4、应该看哪一个数字，1分钟，5分钟还是15分钟？作者认为看5分钟和15分钟的比较好，即后面2个数字。 5、怎样知道我的CPU是几核呢？使用以下命令可以直接获得CPU核心数目 grep ‘model name’ /proc/cpuinfo | wc -l 结论:取得CPU核心数目N，观察后面2个数字，用数字/N，如果得到的值小于0.7即可无忧]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven项目引入外部jar]]></title>
    <url>%2F2018%2F07%2F12%2Farticle-5%2F</url>
    <content type="text"><![CDATA[当我们开发一个功能时发现自己的maven仓库中缺少需要的jar怎么办？ 首先将需要的jar下载下来 然后将jar导入到项目中：webapp/WEB-INF/lib目录下 最后在pom.xml文件中加入依赖就可以编译和打包运行了 1234567&lt;dependency&gt; &lt;groupId&gt;fakepath&lt;/groupId&gt; &lt;artifactId&gt;jxl-report&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;basedir&#125;/src/main/webapp/WEB-INF/lib/jxl-report-1.0.jar&lt;/systemPath&gt;&lt;/dependency&gt; systemPath：导入外部jar的路径${basedir}：项目根目录最终路径为：${basedir}/src/main/webapp/WEB-INF/lib/xxx.jar]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>jar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java实现excel模板导出数据]]></title>
    <url>%2F2018%2F07%2F06%2Farticle-4%2F</url>
    <content type="text"><![CDATA[web项目导出excel有很多种方法，个人觉得使用excel模板导出比较好用，可以满足甲方对excel格式的多种需求，而且实现起来方便。 准备需要的jar：下载地址freemarker-2.3.19.jarfreemarker-util-0.0.1.jarjxl-2.6.10.jarjxl-report-1.0.jarmaven项目pom.xml配置：12345678910111213141516171819202122&lt;!-- excel模板依赖start --&gt;&lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.19&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;net.sourceforge.jexcelapi&lt;/groupId&gt; &lt;artifactId&gt;jxl&lt;/artifactId&gt; &lt;version&gt;2.6.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;fakepath&lt;/groupId&gt; &lt;artifactId&gt;freemarker-util&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;fakepath&lt;/groupId&gt; &lt;artifactId&gt;jxl-report&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- excel模板依赖 end--&gt; java代码实现：1234567891011121314151617181920212223242526272829303132333435@RequestMapping("/exportExcel") @ResponseBody public Map&lt;String,Object&gt; exportExcel(HttpServletRequest request,@RequestBody Map&lt;String, Object&gt; map) throws Exception &#123; logger.info("------------开始执行下载任务-----------"); Map&lt;String,Object&gt; result = new HashMap&lt;String,Object&gt;(); result.put("result",true); result.put("msg","执行成功"); try &#123; String downloadPath="/export";//导出文件夹 //查询导出数据 Map&lt;String,Object&gt; resultMap = reportService.queryExportData(map); //目录生成 ExcelUtil.mkdir(downloadPath); String filename = UUID.randomUUID().toString().replace("-", "").toUpperCase()+".xls"; File f = new File(downloadPath+"/" + File.separatorChar + filename); // 模板生成Excel ReportEnginer enginer = new ReportEnginer(); //模板存储路径 String modelPath = request.getSession().getServletContext().getRealPath("/")+ "/template/model.xls"; InputStream inputStream = new FileInputStream(new File(modelPath)); OutputStream outputStream = new FileOutputStream(f); enginer.excute(inputStream, resultMap, outputStream); inputStream.close(); outputStream.close(); downloadDetail.setResult(filename); &#125; catch (Exception e) &#123; e.printStackTrace(); result.put("result",false); result.put("msg","执行失败"); logger.info("------------下载任务执行失败-----------"); &#125; logger.info("------------下载任务执行完成-----------"); return result; &#125; 代码中resultMap如下：{datalist=[{hours=9, name=张三, cost=10}, {hours=32, name=李四, cost=6}]}excle模板：使用etl表达式结果：]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>excel</tag>
        <tag>java</tag>
        <tag>模板</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客文字增加背景色块]]></title>
    <url>%2F2018%2F06%2F23%2Farticle-3%2F</url>
    <content type="text"><![CDATA[文字配置效果如下： 站点配置文件 主题配置文件 站点配置文件 主题配置文件 打开themes/next/source/css/_custom 下的 custom.styl 文件,添加属性样式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 颜色块-黄span#inline-yellow &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #f0ad4e;&#125;// 颜色块-绿span#inline-green &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #5cb85c;&#125;// 颜色块-蓝span#inline-blue &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #2780e3;&#125;// 颜色块-紫span#inline-purple &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #9954bb;&#125; 在你需要编辑的文章地方。放置如下代码1234&lt;span id="inline-blue"&gt; 站点配置文件 &lt;/span&gt;&lt;span id="inline-purple"&gt; 主题配置文件 &lt;/span&gt;&lt;span id="inline-yellow"&gt; 站点配置文件 &lt;/span&gt;&lt;span id="inline-green"&gt; 主题配置文件 &lt;/span&gt;]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSL证书让网站从HTTP换成HTTPS]]></title>
    <url>%2F2018%2F06%2F15%2Farticle-2%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP 协议是不加密传输数据的，也就是用户跟你的网站之间传递数据有可能在途中被截获，破解传递的真实内容，所以使用不加密的 HTTP 的网站是不太安全的。所以， Google 的 Chrome 浏览器将在 2017 年 1 月开始，标记使用不加密的 HTTP 协议的网站为 Not Secure，不安全。 如何改变呢，有免费的吗？我的服务器和域名都是阿里云申请的，所以下面方法基于阿里云操作。 证书申请登录阿里云后台，找到，产品与服务-》安全（云盾）-》SSL证书（应用安全），找到购买证书进入购买界面后选择”免费型DV SSL”证书，如下图：订单完成后，在订单页面点击“补全”，补全域名（注意现在免费的证书只能使用填写一个域名，且不支持通配符域名配置，因此不支持域名下的二级域名安全认证），然后填写个人信息，按图填写即可：申请审核通过后会收到邮件，意思是云盾证书开通成功 配置SSL证书SSL证书审核通过后在之前的订单页面就可以看到证书下载入口进入下载页面，点击下载按钮“下载证书for Nginx”，下载证书，然后按照提示操作即可以下是阿里提供的方法：安装证书文件说明：1.证书文件214776764040878.pem，包含两段内容，请不要删除任何一段内容。2.如果是证书系统创建的CSR，还包含：证书私钥文件214776764040878.key。( 1 ) 在Nginx的安装目录下创建cert目录，并且将下载的全部文件拷贝到cert目录中。如果申请证书时是自己创建的CSR文件，请将对应的私钥文件放到cert目录下并且命名为214776764040878.key；( 2 ) 打开 Nginx 安装目录下 conf 目录中的 nginx.conf 文件，找到：12345678910111213141516# HTTPS server# #server &#123;# listen 443;# server_name localhost;# ssl on;# ssl_certificate cert.pem;# ssl_certificate_key cert.key;# ssl_session_timeout 5m;# ssl_protocols SSLv2 SSLv3 TLSv1;# ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP;# ssl_prefer_server_ciphers on;# location / &#123;###&#125;#&#125; ( 3 ) 将其修改为 (以下属性中ssl开头的属性与证书配置有直接关系，其它属性请结合自己的实际情况复制或调整) :1234567891011121314151617server &#123; listen 443; server_name localhost; ssl on; root html; index index.html index.htm; ssl_certificate /usr/local/nginx/cert/214776764040878.pem; ssl_certificate_key /usr/local/nginx/cert/214776764040878.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; root html; index index.html index.htm; &#125;&#125; 保存退出。( 4 )重启 Nginx。( 5 ) 通过 https 方式访问您的站点，测试站点证书的安装配置。3.配置443端口SSL使用的443端口，需要服务器开放443端口方法：在阿里云服务器控制台添加安全组，配置443端口监听即可配置后即可通过https访问网站，并且浏览器认证安全参考文档：https://ninghao.net/blog/4449]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
        <tag>SSL证书</tag>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何运行jar程序]]></title>
    <url>%2F2018%2F06%2F14%2Farticle-1%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在开发过程中我们经常将项目打包成war包，打成war的项目就和可以直接放在tomcat和jetty等中间件中运行。那么jar项目怎么运行呢？最近看到springboot比较流行，好奇下弄了个项目跑了起来，然而springboot是jar项目，直接使用主类的main启动项目，那么打包后的项目怎么运行呢？网上查了查，将启动方法放在这里，以便记忆。 Windows系统运行使用dos命令进入jar所在的目录，直接执行执行命令： java -jar xxx.jar可按CTRL + C打断程序运行，或直接关闭窗口，程序退出 linux系统运行方式一： java -jar XXX.jar特点：当前ssh窗口被锁定，可按CTRL + C打断程序运行，或直接关闭窗口，程序退出方式二： java -jar XXX.jar &amp;特点：当前ssh窗口不被锁定，但是当窗口关闭时，程序中止运行。方式三： nohup java -jar XXX.jar &amp;nohup 意思是不挂断运行命令,当账户退出或终端关闭时,程序仍然运行当用 nohup 命令执行作业时，缺省情况下该作业的所有输出被重定向到nohup.out的文件中，除非另外指定了输出文件。方式四： nohup java -jar XXX.jar &gt;temp.txt &amp;解释下 &gt;temp.txtcommand &gt;out.filecommand &gt;out.file是将command的输出重定向到out.file文件，即输出内容不打印到屏幕上，而是输出到out.file文件中。执行nohup命令会执行失败，这时在命令后面加上2&gt;&amp;1 &amp;即可，执行命名如下： nohup java -jar xxx.jar &gt;logs/log.txt 2&gt;&amp;1 &amp;可通过jobs命令查看后台运行任务 jobs那么就会列出所有后台执行的作业，并且每个作业前面都有个编号。如果想将某个作业调回前台控制，只需要 fg + 编号即可。 fg 23查看某端口占用的线程的pid netstat -nlp |grep :9181]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>jar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有人用古文翻译了当下流行话语，对比一下古文有多美！]]></title>
    <url>%2F2018%2F06%2F12%2F%E6%9C%89%E4%BA%BA%E7%94%A8%E5%8F%A4%E6%96%87%E7%BF%BB%E8%AF%91%E4%BA%86%E5%BD%93%E4%B8%8B%E6%B5%81%E8%A1%8C%E8%AF%9D%E8%AF%AD%EF%BC%8C%E5%AF%B9%E6%AF%94%E4%B8%80%E4%B8%8B%E5%8F%A4%E6%96%87%E6%9C%89%E5%A4%9A%E7%BE%8E%EF%BC%81%2F</url>
    <content type="text"><![CDATA[有人用古文翻译了当下流行话语，对比一下古文有多美！ 【一】 原文：每天都被自己帅到睡不着翻译：玉树临风美少年，揽镜自顾夜不眠。原文：有钱，任性。翻译：家有千金，行止由心。 原文：丑的人都睡了，帅的人还醒着。翻译：玉树立风前，驴骡正酣眠。 原文：主要看气质。翻译：请君莫羡解语花，腹有诗书气自华。 原文：也是醉了。翻译：行迈靡靡，中心如醉。 【二】 原文：人要是没有理想，和咸鱼有什么区别。翻译：涸辙遗鲋，旦暮成枯；人而无志，与彼何殊。 原文：别睡了起来嗨。翻译：昼短苦夜长，何不秉烛游。 原文：不要在意这些细节。翻译：欲图大事，莫拘小节。 原文：你这么牛，家里人知道么。翻译：腰中雄剑长三尺，君家严慈知不知。 原文：心好累。翻译：形若槁骸，心如死灰。 【三】 原文：我的内心几乎是崩溃的。翻译：方寸淆乱，灵台崩摧。 原文：你们城里人真会玩。翻译：城中戏一场，山民笑断肠。 原文：我单方面宣布和xx结婚。翻译：愿出一家之言，以结两姓之好。 原文：重要的事说三遍。翻译：一言难尽意，三令作五申。 原文：世界那么大，我想去看看。翻译：天高地阔，欲往观之。 【四】 原文：明明可以靠脸吃饭，偏偏要靠才华。翻译：中华儿女多奇志，不爱红装爱才智。 原文：我读书少，你不要骗我。翻译：君莫欺我不识字，人间安得有此事。 原文：不作死就不会死，为什么不明白。翻译：幸无白刃驱向前，何用将身自弃捐。 原文：你不是一个人在战斗。翻译：岂曰无衣，与子同袍。 原文：我有知识我自豪。翻译：腹有诗书气自华。 原文：说的好有道理，我竟无言以对。翻译：斯言甚善，余不得赞一词。 【五】 原文：秀恩爱，死的快。翻译：爱而不藏，自取其亡。 原文：吓死宝宝了。翻译：堪惊小儿啼，能开长者颐。 原文：沉默不都是金子，有时候还是孙子。翻译：圣人不言如桃李，小民不言若木鸡。 原文：备胎。翻译：章台之柳，已折他人；玄都之花，未改前度。 原文：屌丝终有逆袭日翻译：王侯将相，宁有种乎？]]></content>
      <categories>
        <category>摘录</category>
      </categories>
      <tags>
        <tag>今文古译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 配置Nginx]]></title>
    <url>%2F2018%2F06%2F11%2Flinux-Nginx%2F</url>
    <content type="text"><![CDATA[Nginx 是 C语言 开发，建议在 Linux 上运行，当然，也可以安装 Windows 版本，本篇则使用 CentOS 7 作为安装环境。 首先下载资源包： 安装Nginx之前，首先要安装好编译环境gcc和g++，然后以CentOS为例安装Nginx，安装Nginx需要PRCE库、zlib库和ssl的支持，除了ssl外其他的我们都是去官网下载： Nginx：http://nginx.org/ PCRE：http://www.pcre.org/ zlib：http://www.zlib.net/ 安装所需环境一. gcc 安装安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装： yum install gcc-c++ 二. PCRE pcre-devel 安装PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库。nginx也需要此库。命令： yum install -y pcre pcre-devel 三. zlib 安装zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Centos 上安装 zlib 库。 yum install -y zlib zlib-devel 四. OpenSSL 安装OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 Centos 安装 OpenSSL 库。 yum install -y openssl openssl-devel 安装Nginx：解压Nginx压缩包tar -xvzf nginx-1.9.8.tar.gz，进入解压后文件夹配置：./configure –prefix=/usr/local/nginx –with-http_stub_status_module –with-http_ssl_module –with-http_realip_module 编译1234# make 安装# make install 检查是否安装成功1234cd /usr/local/nginx/sbin ./nginx -t结果显示：nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful 配置防火墙80端口123456#修改防火墙配置： # vi + /etc/sysconfig/iptables #添加配置项 -A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT #重启防火墙 # service iptables restart 启动停止重启与测试1.启动 12345#方法1# /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf#方法2# cd /usr/local/nginx/sbin# ./nginx 2.停止 12345678#查询nginx主进程号 ps -ef | grep nginx#停止进程 kill -QUIT 主进程号 #快速停止 kill -TERM 主进程号 #强制停止 pkill -9 nginx 3.重启(首次启动需：/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf) 1/usr/local/nginx/sbin/nginx -s reload 4.测试 12#测试端口 netstat -na | grep 80]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle 锁表查询和解锁]]></title>
    <url>%2F2018%2F06%2F07%2Foracle-%E9%94%81%E8%A1%A8%E6%9F%A5%E8%AF%A2%E5%92%8C%E8%A7%A3%E9%94%81%2F</url>
    <content type="text"><![CDATA[1.查看里面的锁12345678SELECT b. OWNER, b.object_name, l.session_id, l.locked_modeFROM v$locked_object l, dba_objects bWHERE b.object_id = l.object_id;SELECT t2.username, t2.sid, t2.serial #, t2.logon_timeFROM v$locked_object t1, v$session t2WHERE t1.session_id = t2.sidORDER BY t2.logon_time 2.解锁1alter system kill session 'sid,serial#' 如：1alter system kill session '111,222' 3.查询当前用户的所有活动的session12345select t.SID,t.SERIAL#,t.STATUS,t.STATE,t.SQL_IDfrom v$session twhere t.USERNAME = 'OCN_TDS_DB'and t.STATUS = 'ACTIVE'and t.MACHINE = 'localhost.localdomain'; 4.分析session执行的SQL，尤其是sql_id相同的12#7ykv5kcc4paz2表示当前重复较高的SQL，查询出来发现该SQL主要是用来刷新工单数的。select * from v$sql s where s.SQL_ID='7ykv5kcc4paz2' 5.删除当前应用连接的所有活动session，释放资源1234567#停止Mobile应用，清除所有获取工单数的SQLselect 'alter system kill session '''||t.SID||','||t.SERIAL#||''';'from v$session twhere t.USERNAME = 'OCN_TDS_DB'and t.STATUS = 'ACTIVE'and t.SQL_ID='7ykv5kcc4paz2'and t.MACHINE = 'localhost.localdomain'; 6.根据session_id查询执行的SQL12345678910111213select s.SAMPLE_TIME,sq.SQL_TEXT,sq.DISK_READS,sq.BUFFER_GETS, sq.CPU_TIME,sq.ROWS_PROCESSED,--sq.SQL_FULLTEXT,sq.SQL_IDfrom v$sql sq, v$active_session_history swhere s.SQL_ID = sq.SQL_IDand s.SESSION_ID = 190order by s.SAMPLE_TIME desc;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo常用命令笔记]]></title>
    <url>%2F2018%2F06%2F06%2Fhexo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[hexo npm install hexo -g #安装npm update hexo -g #升级hexo init #初始化 简写 hexo n “我的博客” == hexo new “我的博客” #新建文章 hexo p == hexo publish hexo g == hexo generate#生成 hexo s == hexo server #启动服务预览 hexo d == hexo deploy#部署 服务器 hexo server #Hexo 会监视文件变动并自动更新，您无须重启服务器。hexo server -s #静态模式hexo server -p 5000 #更改端口hexo server -i 192.168.1.1 #自定义 IPhexo clean #清除缓存 网页正常情况下可以忽略此条命令hexo g #生成静态网页hexo d #开始部署 监视文件变动 hexo generate #使用 Hexo 生成静态文件快速而且简单hexo generate –watch #监视文件变动 完成后部署两个命令的作用是相同的 hexo generate –deployhexo deploy –generatehexo deploy -ghexo server -g 草稿 hexo publish [layout] 模版 hexo new “postName” #新建文章hexo new page “pageName” #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server）hexo deploy #将.deploy目录部署到GitHub hexo new [layout] hexo new photo “My Gallery”hexo new “Hello World” –lang tw 变量 描述 layout 布局 title 标题 date 文件建立日期 12345678title: 使用Hexo搭建个人博客&lt;br&gt;layout: post&lt;br&gt;date: 2014-03-03 19:07:43&lt;br&gt;comments: true&lt;br&gt;categories: Blog&lt;br&gt;tags: [Hexo]&lt;br&gt;keywords: Hexo, Blog&lt;br&gt;description: 生命在于折腾，又把博客折腾到Hexo了。给Hexo点赞。 模版（Scaffold） hexo new photo “My Gallery” 变量 描述 layout 布局 title 标题 date 文件建立日期 设置文章摘要以上是文章摘要&lt;!--more--&gt; 以下是余下全文 写作 hexo new page hexo new post 变量 描述 :title 标题 :year 建立的年份（4 位数） :month 建立的月份（2 位数） :i_month 建立的月份（去掉开头的零） :day 建立的日期（2 位数） :i_day 建立的日期（去掉开头的零） 推送到服务器上 hexo n #写文章hexo g #生成hexo d #部署 #可与hexo g合并为 hexo d -g 报错1.找不到git部署1ERROR Deployer not found: git 2.解决方法 npm install hexo-deployer-git –save 3.部署类型设置githexo 3.0 部署类型不再是github，_config.yml 中修改 123456# Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repository: git@***.github.com:***/***.github.io.git branch: master 4. xcodebuildxcode-select: error: tool ‘xcodebuild’ requires Xcode, but active developer directory ‘/Library/Developer/CommandLineTools’ is a command line tools instance npm install bcrypt 5. RSS不显示安装RSS插件 npm install hexo-generator-feed –save 开启RSS功能编辑hexo/_config.yml，添加如下代码： 1rss: /atom.xml #rss地址 默认即可 开启评论1.我使用多说代替自带的评论，在多说 网站注册 &gt; 后台管理 &gt; 添加新站点 &gt; 工具 === 复制通用代码 里面有 short_name 1.在根目录 _config.yml 添加一行 disqus_shortname: jslite 是在多说注册时产生的 2.复制到 themes\landscape\layout\_partial\article.ejs 把 1234567&lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.disqus_shortname)&#123; %&gt;&lt;section id="comments"&gt;&lt;div id="disqus_thread"&gt; &lt;noscript&gt;Please enable JavaScript to view the &lt;a href="//disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/div&gt;&lt;/section&gt;&lt;% &#125; %&gt; 改为 1234567891011121314151617181920&lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.disqus_shortname)&#123; %&gt; &lt;section id="comments"&gt; &lt;!-- 多说评论框 start --&gt; &lt;div class="ds-thread" data-thread-key="&lt;%= post.layout %&gt;-&lt;%= post.slug %&gt;" data-title="&lt;%= post.title %&gt;" data-url="&lt;%= page.permalink %&gt;"&gt;&lt;/div&gt; &lt;!-- 多说评论框 end --&gt; &lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt; &lt;script type="text/javascript"&gt; var duoshuoQuery = &#123;short_name:'&lt;%= config.disqus_shortname %&gt;'&#125;; (function() &#123; var ds = document.createElement('script'); ds.type = 'text/javascript';ds.async = true; ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js'; ds.charset = 'UTF-8'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds); &#125;)(); &lt;/script&gt; &lt;!-- 多说公共JS代码 end --&gt; &lt;/section&gt;&lt;% &#125; %&gt;]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库字段加解密处理]]></title>
    <url>%2F2018%2F06%2F05%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%97%E6%AE%B5%E5%8A%A0%E8%A7%A3%E5%AF%86%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[解决场景： 需要对应用数据存储时采取加密，比如手机号码、地址、证件号方案：其中： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;加解密函数存储在数据库中定义； &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;加解密使用的key在应用中定义（定义后不可改变）； 示例：&nbsp;&nbsp;测试用表： 12345CREATE TABLE `sys_user` (`user_id` BIGINT (20) NOT NULL AUTO_INCREMENT,`user_name` VARCHAR (128) DEFAULT NULL,`user_mobile` VARCHAR (128) DEFAULT NULL,PRIMARY KEY (`user_id`)) ENGINE = INNODB DEFAULT CHARSET = utf8 插入：12345INSERT INTO `sys_user` (`user_name`, `user_mobile`) VALUES( 'smartfoot', DATA_ENCRYPT ('13888888888', 'KEY_ABC')); 存储结果:查询：12345SELECT`user_id`,`user_name`,DATA_DECRYPT (`user_mobile`, 'KEY_ABC') user_mobile FROM `sys_user`; 查询结果:模糊匹配：123456SELECT`user_id`,`user_name`,HG_DECRYPT (`user_mobile`, 'KEY_ABC') user_mobile FROM `sys_user` WHERE HG_DECRYPT (`user_mobile`, 'KEY_ABC') LIKE '138%'; 查询结果: 注意事项： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;加解密函数：加解密函数存储在数据库中定义，与应用无关； &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;key ：加解密使用的key在应用中定义（定义后不可改变）； &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于加密后的长度可变，适当增加加密字段定义长度； Mysql：加密函数:1234567891011121314151617181920DELIMITER $$ DROP FUNCTIONIF EXISTS `DATA_ENCRYPT`$$ CREATE DEFINER = CURRENT_USER FUNCTION `DATA_ENCRYPT` ( p_text VARCHAR (255), p_key VARCHAR (255)) RETURNS VARCHAR (255) CHARSET utf8BEGIN IF (CHAR_LENGTH(p_text) = 0) THEN RETURN '' ;ELSEIF CHAR_LENGTH(p_key) = 0 THEN RETURN p_text ;ELSE RETURN HEX(AES_ENCRYPT(p_text, p_key)) ;ENDIF ; END$$DELIMITER ; 解密函数：12345678910111213141516171819DELIMITER $$DROP FUNCTIONIF EXISTS `DATA_DECRYPT`$$CREATE DEFINER = CURRENT_USER FUNCTION `DATA_DECRYPT` ( p_text VARCHAR (255), p_key VARCHAR (255)) RETURNS VARCHAR (255) CHARSET utf8BEGINIF (CHAR_LENGTH(p_text) = 0) THEN RETURN '' ;ELSEIF CHAR_LENGTH(p_key) = 0 THEN RETURN p_text ;ELSE RETURN AES_DECRYPT(UNHEX(p_text), p_key) ;ENDIF ; END$$DELIMITER ;]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>加密</tag>
      </tags>
  </entry>
</search>
