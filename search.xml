<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[JVM初探- 内存分配、GC原理与垃圾收集器]]></title>
    <url>%2F2018%2F08%2F15%2Fa2%2F</url>
    <content type="text"><![CDATA[JVM内存的分配与回收大致可分为如下4个步骤: 何时分配 -&gt; 怎样分配 -&gt; 何时回收 -&gt; 怎样回收. 除了在概念上可简单认为new时分配外, 我们着重介绍后面的3个步骤: I. 怎样分配- JVM内存分配策略对象内存主要分配在新生代Eden区, 如果启用了本地线程分配缓冲, 则优先在TLAB上分配, 少数情况能会直接分配在老年代, 或被拆分成标量类型在栈上分配(JIT优化). 分配的规则并不是百分百固定, 细节主要取决于垃圾收集器组合, 以及VM内存相关的参数. 对象分配 优先在Eden区分配在JVM内存模型一文中, 我们大致了解了VM年轻代堆内存可以划分为一块Eden区和两块Survivor区. 在大多数情况下, 对象在新生代Eden区中分配, 当Eden区没有足够空间分配时, VM发起一次Minor GC, 将Eden区和其中一块Survivor区内尚存活的对象放入另一块Survivor区域, 如果在Minor GC期间发现新生代存活对象无法放入空闲的Survivor区, 则会通过空间分配担保机制使对象提前进入老年代(空间分配担保见下). 大对象直接进入老年代Serial和ParNew两款收集器提供了-XX:PretenureSizeThreshold的参数, 令大于该值的大对象直接在老年代分配, 这样做的目的是避免在Eden区和Survivor区之间产生大量的内存复制(大对象一般指 需要大量连续内存的Java对象, 如很长的字符串和数组), 因此大对象容易导致还有不少空闲内存就提前触发GC以获取足够的连续空间. 对象晋升 年龄阈值VM为每个对象定义了一个对象年龄(Age)计数器, 对象在Eden出生如果经第一次Minor GC后仍然存活, 且能被Survivor容纳的话, 将被移动到Survivor空间中, 并将年龄设为1. 以后对象在Survivor区中每熬过一次Minor GC年龄就+1. 当增加到一定程度(-XX:MaxTenuringThreshold, 默认15), 将会晋升到老年代. 提前晋升: 动态年龄判定然而VM并不总是要求对象的年龄必须达到MaxTenuringThreshold才能晋升老年代: 如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半, 年龄大于或等于该年龄的对象就可以直接进入老年代, 而无须等到晋升年龄. II. 何时回收-对象生死判定(哪些内存需要回收/何时回收) 在堆里面存放着Java世界中几乎所有的对象实例, 垃圾收集器在对堆进行回收前, 第一件事就是判断哪些对象已死(可回收). 可达性分析算法在主流商用语言(如Java、C#)的主流实现中, 都是通过可达性分析算法来判定对象是否存活的: 通过一系列的称为 GC Roots 的对象作为起点, 然后向下搜索; 搜索所走过的路径称为引用链/Reference Chain, 当一个对象到 GC Roots 没有任何引用链相连时, 即该对象不可达, 也就说明此对象是不可用的, 如下图: Object5、6、7 虽然互有关联, 但它们到GC Roots是不可达的, 因此也会被判定为可回收的对象: 在Java, 可作为GC Roots的对象包括: 方法区: 类静态属性引用的对象; 方法区: 常量引用的对象; 虚拟机栈(本地变量表)中引用的对象. 本地方法栈JNI(Native方法)中引用的对象。 注: 即使在可达性分析算法中不可达的对象, VM也并不是马上对其回收, 因为要真正宣告一个对象死亡, 至少要经历两次标记过程: 第一次是在可达性分析后发现没有与GC Roots相连接的引用链, 第二次是GC对在F-Queue执行队列中的对象进行的小规模标记(对象需要覆盖finalize()方法且没被调用过). III. GC原理- 垃圾收集算法分代收集算法 VS 分区收集算法 分代收集当前主流VM垃圾收集都采用”分代收集”(Generational Collection)算法, 这种算法会根据对象存活周期的不同将内存划分为几块, 如JVM中的 新生代、老年代、永久代. 这样就可以根据各年代特点分别采用最适当的GC算法: 在新生代: 每次垃圾收集都能发现大批对象已死, 只有少量存活. 因此选用复制算法, 只需要付出少量存活对象的复制成本就可以完成收集. 在老年代: 因为对象存活率高、没有额外空间对它进行分配担保, 就必须采用“标记—清理”或“标记—整理”算法来进行回收, 不必进行内存复制, 且直接腾出空闲内存. 分区收集上面介绍的分代收集算法是将对象的生命周期按长短划分为两个部分, 而分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的好处是可以控制一次回收多少个小区间.在相同条件下, 堆空间越大, 一次GC耗时就越长, 从而产生的停顿也越长. 为了更好地控制GC产生的停顿时间, 将一块大的内存区域分割为多个小块, 根据目标停顿时间, 每次合理地回收若干个小区间(而不是整个堆), 从而减少一次GC所产生的停顿. 分代收集新生代-复制算法该算法的核心是将可用内存按容量划分为大小相等的两块, 每次只用其中一块, 当这一块的内存用完, 就将还存活的对象复制到另外一块上面, 然后把已使用过的内存空间一次清理掉. (图片来源: jvm垃圾收集算)这使得每次只对其中一块内存进行回收, 分配也就不用考虑内存碎片等复杂情况, 实现简单且运行高效. 现代商用VM的新生代均采用复制算法, 但由于新生代中的98%的对象都是生存周期极短的, 因此并不需完全按照1∶1的比例划分新生代空间, 而是将新生代划分为一块较大的Eden区和两块较小的Survivor区(HotSpot默认Eden和Survivor的大小比例为8∶1), 每次只用Eden和其中一块Survivor. 当发生MinorGC时, 将Eden和Survivor中还存活着的对象一次性地拷贝到另外一块Survivor上, 最后清理掉Eden和刚才用过的Survivor的空间. 当Survivor空间不够用(不足以保存尚存活的对象)时, 需要依赖老年代进行空间分配担保机制, 这部分内存直接进入老年代. 老年代-标记清除算法该算法分为“标记”和“清除”两个阶段: 首先标记出所有需要回收的对象(可达性分析), 在标记完成后统一清理掉所有被标记的对象. 该算法会有以下两个问题: 效率问题: 标记和清除过程的效率都不高; 空间问题: 标记清除后会产生大量不连续的内存碎片, 空间碎片太多可能会导致在运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集. 老年代-标记整理算法标记清除算法会产生内存碎片问题, 而复制算法需要有额外的内存担保空间, 于是针对老年代的特点, 又有了标记整理算法. 标记整理算法的标记过程与标记清除算法相同, 但后续步骤不再对可回收对象直接清理, 而是让所有存活的对象都向一端移动,然后清理掉端边界以外的内存. 永久代-方法区回收 在方法区进行垃圾回收一般”性价比”较低, 因为在方法区主要回收两部分内容: 废弃常量和无用的类. 回收废弃常量与回收其他年代中的对象类似, 但要判断一个类是否无用则条件相当苛刻: 该类所有的实例都已经被回收, Java堆中不存在该类的任何实例; 该类对应的Class对象没有在任何地方被引用(也就是在任何地方都无法通过反射访问该类的方法); 加载该类的ClassLoader已经被回收.但即使满足以上条件也未必一定会回收, Hotspot VM还提供了-Xnoclassgc参数控制(关闭CLASS的垃圾回收功能). 因此在大量使用动态代理、CGLib等字节码框架的应用中一定要关闭该选项, 开启VM的类卸载功能, 以保证方法区不会溢出. 补充: 空间分配担保在执行Minor GC前, VM会首先检查老年代是否有足够的空间存放新生代尚存活对象, 由于新生代使用复制收集算法, 为了提升内存利用率, 只使用了其中一个Survivor作为轮换备份, 因此当出现大量对象在Minor GC后仍然存活的情况时, 就需要老年代进行分配担保, 让Survivor无法容纳的对象直接进入老年代, 但前提是老年代需要有足够的空间容纳这些存活对象. 但存活对象的大小在实际完成GC前是无法明确知道的, 因此Minor GC前, VM会先首先检查老年代连续空间是否大于新生代对象总大小或历次晋升的平均大小, 如果条件成立, 则进行Minor GC, 否则进行Full GC(让老年代腾出更多空间).然而取历次晋升的对象的平均大小也是有一定风险的, 如果某次Minor GC存活后的对象突增,远远高于平均值的话,依然可能导致担保失败(Handle Promotion Failure, 老年代也无法存放这些对象了), 此时就只好在失败后重新发起一次Full GC(让老年代腾出更多空间). IX. GC实现- 垃圾收集器 GC实现目标: 准确、高效、低停顿、空闲内存规整. 新生代1. Serial收集器Serial收集器是Hotspot运行在Client模式下的默认新生代收集器, 它的特点是 只用一个CPU/一条收集线程去完成GC工作, 且在进行垃圾收集时必须暂停其他所有的工作线程(“Stop The World” -后面简称STW). 虽然是单线程收集, 但它却简单而高效, 在VM管理内存不大的情况下(收集几十M~一两百M的新生代), 停顿时间完全可以控制在几十毫秒~一百多毫秒内. 2. ParNew收集器ParNew收集器其实是前面Serial的多线程版本, 除使用多条线程进行GC外, 包括Serial可用的所有控制参数、收集算法、STW、对象分配规则、回收策略等都与Serial完全一样(也是VM启用CMS收集器-XX: +UseConcMarkSweepGC的默认新生代收集器). 由于存在线程切换的开销, ParNew在单CPU的环境中比不上Serial, 且在通过超线程技术实现的两个CPU的环境中也不能100%保证能超越Serial. 但随着可用的CPU数量的增加, 收集效率肯定也会大大增加(ParNew收集线程数与CPU的数量相同, 因此在CPU数量过大的环境中, 可用-XX:ParallelGCThreads参数控制GC线程数). 3. Parallel Scavenge收集器与ParNew类似, Parallel Scavenge也是使用复制算法, 也是并行多线程收集器. 但与其他收集器关注尽可能缩短垃圾收集时间不同, Parallel Scavenge更关注系统吞吐量:系统吞吐量=运行用户代码时间(运行用户代码时间+垃圾收集时间)停顿时间越短就越适用于用户交互的程序-良好的响应速度能提升用户的体验;而高吞吐量则适用于后台运算而不需要太多交互的任务-可以最高效率地利用CPU时间,尽快地完成程序的运算任务. Parallel Scavenge提供了如下参数设置系统吞吐量: Parallel Scavenge参数 描述 MaxGCPauseMillis (毫秒数) 收集器将尽力保证内存回收花费的时间不超过设定值, 但如果太小将会导致GC的频率增加. GCTimeRatio (整数:0 &lt; GCTimeRatio &lt; 100) 是垃圾收集时间占总时间的比率 -XX:+UseAdaptiveSizePolicy 启用GC自适应的调节策略: 不再需要手工指定-Xmn、-XX:SurvivorRatio、-XX:PretenureSizeThreshold等细节参数, VM会根据当前系统的运行情况收集性能监控信息, 动态调整这些参数以提供最合适的停顿时间或最大的吞吐量 老年代Serial Old收集器Serial Old是Serial收集器的老年代版本, 同样是单线程收集器,使用“标记-整理”算法: Serial Old应用场景如下: JDK 1.5之前与Parallel Scavenge收集器搭配使用; 作为CMS收集器的后备预案, 在并发收集发生Concurrent Mode Failure时启用(见下:CMS收集器). Parallel Old收集器Parallel Old是Parallel Scavenge收老年代版本, 使用多线程和“标记－整理”算法, 吞吐量优先, 主要与Parallel Scavenge配合在 注重吞吐量 及 CPU资源敏感 系统内使用: CMS收集器CMS(Concurrent Mark Sweep)收集器是一款具有划时代意义的收集器, 一款真正意义上的并发收集器, 虽然现在已经有了理论意义上表现更好的G1收集器, 但现在主流互联网企业线上选用的仍是CMS(如Taobao、微店).CMS是一种以获取最短回收停顿时间为目标的收集器(CMS又称多并发低暂停的收集器), 基于”标记-清除”算法实现, 整个GC过程分为以下4个步骤: 初始标记(CMS initial mark) 并发标记(CMS concurrent mark: GC Roots Tracing过程) 重新标记(CMS remark) 并发清除(CMS concurrent sweep: 已死象将会就地释放, 注意: 此处没有压缩) 其中两个加粗的步骤(初始标记、重新标记)仍需STW. 但初始标记仅只标记一下GC Roots能直接关联到的对象, 速度很快; 而重新标记则是为了修正并发标记期间因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录, 虽然一般比初始标记阶段稍长, 但要远小于并发标记时间. (由于整个GC过程耗时最长的并发标记和并发清除阶段的GC线程可与用户线程一起工作, 所以总体上CMS的GC过程是与用户线程一起并发地执行的.由于CMS收集器将整个GC过程进行了更细粒度的划分, 因此可以实现并发收集、低停顿的优势, 但它也并非十分完美, 其存在缺点及解决策略如下: CMS默认启动的回收线程数=(CPU数目+3)/4当CPU数&gt;4时, GC线程最多占用不超过25%的CPU资源, 但是当CPU数&lt;=4时, GC线程可能就会过多的占用用户CPU资源, 从而导致应用程序变慢, 总吞吐量降低. 无法处理浮动垃圾, 可能出现Promotion Failure、Concurrent Mode Failure而导致另一次Full GC的产生: 浮动垃圾是指在CMS并发清理阶段用户线程运行而产生的新垃圾. 由于在GC阶段用户线程还需运行, 因此还需要预留足够的内存空间给用户线程使用, 导致CMS不能像其他收集器那样等到老年代几乎填满了再进行收集. 因此CMS提供了-XX:CMSInitiatingOccupancyFraction参数来设置GC的触发百分比(以及-XX:+UseCMSInitiatingOccupancyOnly来启用该触发百分比), 当老年代的使用空间超过该比例后CMS就会被触发(JDK 1.6之后默认92%). 但当CMS运行期间预留的内存无法满足程序需要, 就会出现上述Promotion Failure等失败, 这时VM将启动后备预案: 临时启用Serial Old收集器来重新执行Full GC(CMS通常配合大内存使用, 一旦大内存转入串行的Serial GC, 那停顿的时间就是大家都不愿看到的了). 最后, 由于CMS采用”标记-清除”算法实现, 可能会产生大量内存碎片. 内存碎片过多可能会导致无法分配大对象而提前触发Full GC. 因此CMS提供了-XX:+UseCMSCompactAtFullCollection开关参数, 用于在Full GC后再执行一个碎片整理过程. 但内存整理是无法并发的, 内存碎片问题虽然没有了, 但停顿时间也因此变长了, 因此CMS还提供了另外一个参数-XX:CMSFullGCsBeforeCompaction用于设置在执行N次不进行内存整理的Full GC后, 跟着来一次带整理的(默认为0: 每次进入Full GC时都进行碎片整理). 分区收集- G1收集器 G1(Garbage-First)是一款面向服务端应用的收集器, 主要目标用于配备多颗CPU的服务器治理大内存. G1 is planned as the long term replacement for the Concurrent Mark-Sweep Collector (CMS). -XX:+UseG1GC 启用G1收集器. 与其他基于分代的收集器不同, G1将整个Java堆划分为多个大小相等的独立区域(Region), 虽然还保留有新生代和老年代的概念, 但新生代和老年代不再是物理隔离的了, 它们都是一部分Region(不需要连续)的集合. 每块区域既有可能属于O区、也有可能是Y区, 因此不需要一次就对整个老年代/新生代回收. 而是当线程并发寻找可回收的对象时, 有些区块包含可回收的对象要比其他区块多很多. 虽然在清理这些区块时G1仍然需要暂停应用线程, 但可以用相对较少的时间优先回收垃圾较多的Region(这也是G1命名的来源). 这种方式保证了G1可以在有限的时间内获取尽可能高的收集效率. 新生代收集G1的新生代收集跟ParNew类似: 存活的对象被转移到一个/多个Survivor Regions. 如果存活时间达到阀值, 这部分对象就会被提升到老年代. G1的新生代收集特点如下: 一整块堆内存被分为多个Regions. 存活对象被拷贝到新的Survivor区或老年代. 年轻代内存由一组不连续的heap区组成, 这种方法使得可以动态调整各代区域尺寸. Young GCs会有STW事件, 进行时所有应用程序线程都会被暂停. 多线程并发GC. 老年代收集G1老年代GC会执行以下阶段: 注: 一下有些阶段也是年轻代垃圾收集的一部分. index Phase Description (1) 初始标记 (Initial Mark: Stop the World Event) 在G1中, 该操作附着一次年轻代GC, 以标记Survivor中有可能引用到老年代对象的Regions. (2) 扫描根区域 (Root Region Scanning: 与应用程序并发执行) 扫描Survivor中能够引用到老年代的references. 但必须在Minor GC触发前执行完. (3) 并发标记 (Concurrent Marking : 与应用程序并发执行) 在整个堆中查找存活对象, 但该阶段可能会被Minor GC中断. (4) 重新标记 (Remark : Stop the World Event) 完成堆内存中存活对象的标记. 使用snapshot-at-the-beginning(SATB, 起始快照)算法, 比CMS所用算法要快得多(空Region直接被移除并回收, 并计算所有区域的活跃度). (5) 清理 (Cleanup : Stop the World Event and Concurrent) 见下 5-1、2、3 5-1 (Stop the world) 在含有存活对象和完全空闲的区域上进行统计 5-2 (Stop the world) 擦除Remembered Sets. 5-3 (Concurrent) 重置空regions并将他们返还给空闲列表(free list) (*) Copying/Cleanup (Stop the World Event) 选择”活跃度”最低的区域(这些区域可以最快的完成回收). 拷贝/转移存活的对象到新的尚未使用的regions. 该阶段会被记录在gc-log内(只发生年轻代[GC pause (young)], 与老年代一起执行则被记录为[GC Pause (mixed)]. 详细步骤可参考 Oracle官方文档-The G1 Garbage Collector Step by Step. G1老年代GC特点如下: 并发标记阶段(index 3) 在与应用程序并发执行的过程中会计算活跃度信息. 这些活跃度信息标识出那些regions最适合在STW期间回收(which regions will be best to reclaim during an evacuation pause). 不像CMS有清理阶段. 再次标记阶段(index 4) 使用Snapshot-at-the-Beginning(SATB)算法比CMS快得多. 空region直接被回收. 拷贝/清理阶段(Copying/Cleanup Phase) 年轻代与老年代同时回收. 老年代内存回收会基于他的活跃度信息. 补充: 关于Remembered SetG1收集器中, Region之间的对象引用以及其他收集器中的新生代和老年代之间的对象引用都是使用Remembered Set来避免扫描全堆. G1中每个Region都有一个与之对应的Remembered Set, VM发现程序对Reference类型数据进行写操作时, 会产生一个Write Barrier暂时中断写操作, 检查Reference引用的对象是否处于不同的Region中(在分代例子中就是检查是否老年代中的对象引用了新生代的对象), 如果是, 便通过CardTable把相关引用信息记录到被引用对象所属的Region的Remembered Set中. 当内存回收时, 在GC根节点的枚举范围加入Remembered Set即可保证不对全局堆扫描也不会有遗漏. V. JVM小工具在${JAVA_HOME}/bin/目录下Sun/Oracle给我们提供了一些处理应用程序性能问题、定位故障的工具, 包含 bin 描述 功能 jps 打印Hotspot VM进程 VMID、JVM参数、main()函数参数、主类名/Jar路径 jstat 查看Hotspot VM 运行时信息 类加载、内存、GC[可分代查看]、JIT编译 jinfo 查看和修改虚拟机各项配置 -flag name=value jmap heapdump: 生成VM堆转储快照、查询finalize执行队列、Java堆和永久代详细信息 jmap -dump:live,format=b,file=heap.bin [VMID] jstack 查看VM当前时刻的线程快照: 当前VM内每一条线程正在执行的方法堆栈集合 Thread.getAllStackTraces()提供了类似的功能 javap 查看经javac之后产生的JVM字节码代码 自动解析.class文件, 避免了去理解class文件格式以及手动解析class文件内容 jcmd 一个多功能工具, 可以用来导出堆, 查看Java进程、导出线程信息、 执行GC、查看性能相关数据等 几乎集合了jps、jstat、jinfo、jmap、jstack所有功能 jconsole 基于JMX的可视化监视、管理工具 可以查看内存、线程、类、CPU信息, 以及对JMX MBean进行管理 jvisualvm JDK中最强大运行监视和故障处理工具 可以监控内存泄露、跟踪垃圾回收、执行时内存分析、CPU分析、线程分析… VI. VM常用参数整理 参数 描述 -Xms 最小堆大小 -Xmx 最大堆大小 -Xmn 新生代大小 -XX:PermSize 永久代大小 -XX:MaxPermSize 永久代最大大小 -XX:+PrintGC 输出GC日志 -verbose:gc - -XX:+PrintGCDetails 输出GC的详细日志 -XX:+PrintGCTimeStamps 输出GC时间戳(以基准时间的形式) -XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息 -Xloggc:/path/gc.log 日志文件的输出路径 -XX:+PrintGCApplicationStoppedTime 打印由GC产生的停顿时间 在此处无法列举所有的参数以及他们的应用场景, 详细移步Oracle官方文档-Java HotSpot VM Options. 参考 &amp; 扩展深入理解Java虚拟机JVM内幕：Java虚拟机详解 (力荐)JVM中的G1垃圾回收器G1垃圾收集器入门Getting Started with the G1 Garbage Collector深入理解G1垃圾收集器解析JDK 7的Garbage-First收集器The Garbage-First Garbage CollectorMemory Management in the Java HotSpot Virtual MachineJava HotSpot VM OptionsJVM实用参数（一）JVM类型以及编译器模式JVM内存回收理论与实现基于OpenJDK深度定制的淘宝JVM（TaobaoVM） 原文出处： JVM初探- 内存分配、GC原理与垃圾收集器]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统平均负载指标解读]]></title>
    <url>%2F2018%2F08%2F13%2Fa1%2F</url>
    <content type="text"><![CDATA[一.使用top命令,看到右上角有个平均负载指标12345678top - 11:47:03 up 356 days, 20:33, 8 users, load average: 10.08, 11.02, 12.23Tasks: 159 total, 3 running, 156 sleeping, 0 stopped, 0 zombie%Cpu0 : 55.8 us, 11.5 sy, 0.0 ni, 17.3 id, 0.0 wa, 0.0 hi, 15.4 si, 0.0 st%Cpu1 : 36.7 us, 16.3 sy, 0.0 ni, 46.9 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 37.3 us, 15.7 sy, 0.0 ni, 47.1 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 30.8 us, 11.5 sy, 0.0 ni, 57.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 16268500 total, 169076 free, 8331188 used, 7768236 buff/cacheKiB Swap: 0 total, 0 free, 0 used. 7399704 avail Mem 当前cpu为4核逻辑处理器,如上所示,怎么判断当前系统是否超载?参考:https://blog.csdn.net/chenxiao_ji/article/details/46897695在Linux shell下，有很多命令可以看到Load Average，例如：12root@Slyar.com:~# uptime12:49:10 up 182 days, 16:54, 2 users, load average: 0.08, 0.04, 0.01 12root@Slyar.com:~# toptop - 12:50:28 up 182 days, 16:55, 2 users, load average: 0.02, 0.05, 0.00 先大致给一下这3个数字的含义：分别表示系统在过去1分钟、5分钟、15分钟内运行进程队列中的平均进程数量。运行队列嘛，没有等待IO，没有WAIT，没有KILL的进程通通都进这个队列。另外还有一个最直接的显示系统平均负载的命令12[172.23.6.189:hadoop@sz-pg-smce-cce-016:/home/hadoop]$ cat /proc/loadavg 12.04 11.32 12.15 26/664 6142 除了前3个数字表示平均进程数量外，后面的1个分数，分母表示系统进程总数，分子表示正在运行的进程数；最后一个数字表示最近运行的进程ID. 二.系统平均负载-进阶解释只是上面那一句话的解释，基本等于没解释。写这篇文章的缘由就是因为看到了一篇老外写的关于Load Average的文章，觉得解释的很好，所以才打算摘取一部分用自己的话翻译一下。@scoutapp Thanks for your article Understanding Linux CPU Load, I just translate and share it to Chinese audiences. 为了更好地理解系统负载，我们用交通流量来做类比。1、单核CPU - 单车道 - 数字在0.00-1.00之间正常路况管理员会告知司机，如果前面比较拥堵，那司机就要等待，如果前面一路畅通，那么司机就可以驾车直接开过。具体来说：0.00-1.00 之间的数字表示此时路况非常良好，没有拥堵，车辆可以毫无阻碍地通过。1.00 表示道路还算正常，但有可能会恶化并造成拥堵。此时系统已经没有多余的资源了，管理员需要进行优化。1.00-*** 表示路况不太好了，如果到达2.00表示有桥上车辆一倍数目的车辆正在等待。这种情况你必须进行检查了。到这里,可以判断,单核CPU处理时,平均负载数超过&gt;=2(一般看近5分钟,中间数值),即CPU出现超载 2、多核CPU - 多车道 - 数字/CPU核数 在0.00-1.00之间正常多核CPU的话，满负荷状态的数字为 “1.00 * CPU核数”，即双核CPU为2.00，四核CPU为4.00。 3、安全的系统平均负载作者认为单核负载在0.7以下是安全的，超过0.7就需要进行优化了。 4、应该看哪一个数字，1分钟，5分钟还是15分钟？作者认为看5分钟和15分钟的比较好，即后面2个数字。 5、怎样知道我的CPU是几核呢？使用以下命令可以直接获得CPU核心数目 grep ‘model name’ /proc/cpuinfo | wc -l 结论:取得CPU核心数目N，观察后面2个数字，用数字/N，如果得到的值小于0.7即可无忧]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven项目引入外部jar]]></title>
    <url>%2F2018%2F07%2F12%2Farticle-5%2F</url>
    <content type="text"><![CDATA[当我们开发一个功能时发现自己的maven仓库中缺少需要的jar怎么办？ 首先将需要的jar下载下来 然后将jar导入到项目中：webapp/WEB-INF/lib目录下 最后在pom.xml文件中加入依赖就可以编译和打包运行了 1234567&lt;dependency&gt; &lt;groupId&gt;fakepath&lt;/groupId&gt; &lt;artifactId&gt;jxl-report&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;basedir&#125;/src/main/webapp/WEB-INF/lib/jxl-report-1.0.jar&lt;/systemPath&gt;&lt;/dependency&gt; systemPath：导入外部jar的路径${basedir}：项目根目录最终路径为：${basedir}/src/main/webapp/WEB-INF/lib/xxx.jar]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>jar</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java实现excel模板导出数据]]></title>
    <url>%2F2018%2F07%2F06%2Farticle-4%2F</url>
    <content type="text"><![CDATA[web项目导出excel有很多种方法，个人觉得使用excel模板导出比较好用，可以满足甲方对excel格式的多种需求，而且实现起来方便。 准备需要的jar：下载地址freemarker-2.3.19.jarfreemarker-util-0.0.1.jarjxl-2.6.10.jarjxl-report-1.0.jarmaven项目pom.xml配置：12345678910111213141516171819202122&lt;!-- excel模板依赖start --&gt;&lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.19&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;net.sourceforge.jexcelapi&lt;/groupId&gt; &lt;artifactId&gt;jxl&lt;/artifactId&gt; &lt;version&gt;2.6.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;fakepath&lt;/groupId&gt; &lt;artifactId&gt;freemarker-util&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;fakepath&lt;/groupId&gt; &lt;artifactId&gt;jxl-report&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- excel模板依赖 end--&gt; java代码实现：1234567891011121314151617181920212223242526272829303132333435@RequestMapping("/exportExcel") @ResponseBody public Map&lt;String,Object&gt; exportExcel(HttpServletRequest request,@RequestBody Map&lt;String, Object&gt; map) throws Exception &#123; logger.info("------------开始执行下载任务-----------"); Map&lt;String,Object&gt; result = new HashMap&lt;String,Object&gt;(); result.put("result",true); result.put("msg","执行成功"); try &#123; String downloadPath="/export";//导出文件夹 //查询导出数据 Map&lt;String,Object&gt; resultMap = reportService.queryExportData(map); //目录生成 ExcelUtil.mkdir(downloadPath); String filename = UUID.randomUUID().toString().replace("-", "").toUpperCase()+".xls"; File f = new File(downloadPath+"/" + File.separatorChar + filename); // 模板生成Excel ReportEnginer enginer = new ReportEnginer(); //模板存储路径 String modelPath = request.getSession().getServletContext().getRealPath("/")+ "/template/model.xls"; InputStream inputStream = new FileInputStream(new File(modelPath)); OutputStream outputStream = new FileOutputStream(f); enginer.excute(inputStream, resultMap, outputStream); inputStream.close(); outputStream.close(); downloadDetail.setResult(filename); &#125; catch (Exception e) &#123; e.printStackTrace(); result.put("result",false); result.put("msg","执行失败"); logger.info("------------下载任务执行失败-----------"); &#125; logger.info("------------下载任务执行完成-----------"); return result; &#125; 代码中resultMap如下：{datalist=[{hours=9, name=张三, cost=10}, {hours=32, name=李四, cost=6}]}excle模板：使用etl表达式结果：]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>excel</tag>
        <tag>java</tag>
        <tag>模板</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客文字增加背景色块]]></title>
    <url>%2F2018%2F06%2F23%2Farticle-3%2F</url>
    <content type="text"><![CDATA[文字配置效果如下： 站点配置文件 主题配置文件 站点配置文件 主题配置文件 打开themes/next/source/css/_custom 下的 custom.styl 文件,添加属性样式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 颜色块-黄span#inline-yellow &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #f0ad4e;&#125;// 颜色块-绿span#inline-green &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #5cb85c;&#125;// 颜色块-蓝span#inline-blue &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #2780e3;&#125;// 颜色块-紫span#inline-purple &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #9954bb;&#125; 在你需要编辑的文章地方。放置如下代码1234&lt;span id="inline-blue"&gt; 站点配置文件 &lt;/span&gt;&lt;span id="inline-purple"&gt; 主题配置文件 &lt;/span&gt;&lt;span id="inline-yellow"&gt; 站点配置文件 &lt;/span&gt;&lt;span id="inline-green"&gt; 主题配置文件 &lt;/span&gt;]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSL证书让网站从HTTP换成HTTPS]]></title>
    <url>%2F2018%2F06%2F15%2Farticle-2%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP 协议是不加密传输数据的，也就是用户跟你的网站之间传递数据有可能在途中被截获，破解传递的真实内容，所以使用不加密的 HTTP 的网站是不太安全的。所以， Google 的 Chrome 浏览器将在 2017 年 1 月开始，标记使用不加密的 HTTP 协议的网站为 Not Secure，不安全。 如何改变呢，有免费的吗？我的服务器和域名都是阿里云申请的，所以下面方法基于阿里云操作。 证书申请登录阿里云后台，找到，产品与服务-》安全（云盾）-》SSL证书（应用安全），找到购买证书进入购买界面后选择”免费型DV SSL”证书，如下图：订单完成后，在订单页面点击“补全”，补全域名（注意现在免费的证书只能使用填写一个域名，且不支持通配符域名配置，因此不支持域名下的二级域名安全认证），然后填写个人信息，按图填写即可：申请审核通过后会收到邮件，意思是云盾证书开通成功 配置SSL证书SSL证书审核通过后在之前的订单页面就可以看到证书下载入口进入下载页面，点击下载按钮“下载证书for Nginx”，下载证书，然后按照提示操作即可以下是阿里提供的方法：安装证书文件说明：1.证书文件214776764040878.pem，包含两段内容，请不要删除任何一段内容。2.如果是证书系统创建的CSR，还包含：证书私钥文件214776764040878.key。( 1 ) 在Nginx的安装目录下创建cert目录，并且将下载的全部文件拷贝到cert目录中。如果申请证书时是自己创建的CSR文件，请将对应的私钥文件放到cert目录下并且命名为214776764040878.key；( 2 ) 打开 Nginx 安装目录下 conf 目录中的 nginx.conf 文件，找到：12345678910111213141516# HTTPS server# #server &#123;# listen 443;# server_name localhost;# ssl on;# ssl_certificate cert.pem;# ssl_certificate_key cert.key;# ssl_session_timeout 5m;# ssl_protocols SSLv2 SSLv3 TLSv1;# ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP;# ssl_prefer_server_ciphers on;# location / &#123;###&#125;#&#125; ( 3 ) 将其修改为 (以下属性中ssl开头的属性与证书配置有直接关系，其它属性请结合自己的实际情况复制或调整) :1234567891011121314151617server &#123; listen 443; server_name localhost; ssl on; root html; index index.html index.htm; ssl_certificate /usr/local/nginx/cert/214776764040878.pem; ssl_certificate_key /usr/local/nginx/cert/214776764040878.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; root html; index index.html index.htm; &#125;&#125; 保存退出。( 4 )重启 Nginx。( 5 ) 通过 https 方式访问您的站点，测试站点证书的安装配置。3.配置443端口SSL使用的443端口，需要服务器开放443端口方法：在阿里云服务器控制台添加安全组，配置443端口监听即可配置后即可通过https访问网站，并且浏览器认证安全参考文档：https://ninghao.net/blog/4449]]></content>
      <categories>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
        <tag>SSL证书</tag>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何运行jar程序]]></title>
    <url>%2F2018%2F06%2F14%2Farticle-1%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在开发过程中我们经常将项目打包成war包，打成war的项目就和可以直接放在tomcat和jetty等中间件中运行。那么jar项目怎么运行呢？最近看到springboot比较流行，好奇下弄了个项目跑了起来，然而springboot是jar项目，直接使用主类的main启动项目，那么打包后的项目怎么运行呢？网上查了查，将启动方法放在这里，以便记忆。 Windows系统运行使用dos命令进入jar所在的目录，直接执行执行命令： java -jar xxx.jar可按CTRL + C打断程序运行，或直接关闭窗口，程序退出 linux系统运行方式一： java -jar XXX.jar特点：当前ssh窗口被锁定，可按CTRL + C打断程序运行，或直接关闭窗口，程序退出方式二： java -jar XXX.jar &amp;特点：当前ssh窗口不被锁定，但是当窗口关闭时，程序中止运行。方式三： nohup java -jar XXX.jar &amp;nohup 意思是不挂断运行命令,当账户退出或终端关闭时,程序仍然运行当用 nohup 命令执行作业时，缺省情况下该作业的所有输出被重定向到nohup.out的文件中，除非另外指定了输出文件。方式四： nohup java -jar XXX.jar &gt;temp.txt &amp;解释下 &gt;temp.txtcommand &gt;out.filecommand &gt;out.file是将command的输出重定向到out.file文件，即输出内容不打印到屏幕上，而是输出到out.file文件中。执行nohup命令会执行失败，这时在命令后面加上2&gt;&amp;1 &amp;即可，执行命名如下： nohup java -jar xxx.jar &gt;logs/log.txt 2&gt;&amp;1 &amp;可通过jobs命令查看后台运行任务 jobs那么就会列出所有后台执行的作业，并且每个作业前面都有个编号。如果想将某个作业调回前台控制，只需要 fg + 编号即可。 fg 23查看某端口占用的线程的pid netstat -nlp |grep :9181]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>jar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有人用古文翻译了当下流行话语，对比一下古文有多美！]]></title>
    <url>%2F2018%2F06%2F12%2F%E6%9C%89%E4%BA%BA%E7%94%A8%E5%8F%A4%E6%96%87%E7%BF%BB%E8%AF%91%E4%BA%86%E5%BD%93%E4%B8%8B%E6%B5%81%E8%A1%8C%E8%AF%9D%E8%AF%AD%EF%BC%8C%E5%AF%B9%E6%AF%94%E4%B8%80%E4%B8%8B%E5%8F%A4%E6%96%87%E6%9C%89%E5%A4%9A%E7%BE%8E%EF%BC%81%2F</url>
    <content type="text"><![CDATA[有人用古文翻译了当下流行话语，对比一下古文有多美！ 【一】 原文：每天都被自己帅到睡不着翻译：玉树临风美少年，揽镜自顾夜不眠。原文：有钱，任性。翻译：家有千金，行止由心。 原文：丑的人都睡了，帅的人还醒着。翻译：玉树立风前，驴骡正酣眠。 原文：主要看气质。翻译：请君莫羡解语花，腹有诗书气自华。 原文：也是醉了。翻译：行迈靡靡，中心如醉。 【二】 原文：人要是没有理想，和咸鱼有什么区别。翻译：涸辙遗鲋，旦暮成枯；人而无志，与彼何殊。 原文：别睡了起来嗨。翻译：昼短苦夜长，何不秉烛游。 原文：不要在意这些细节。翻译：欲图大事，莫拘小节。 原文：你这么牛，家里人知道么。翻译：腰中雄剑长三尺，君家严慈知不知。 原文：心好累。翻译：形若槁骸，心如死灰。 【三】 原文：我的内心几乎是崩溃的。翻译：方寸淆乱，灵台崩摧。 原文：你们城里人真会玩。翻译：城中戏一场，山民笑断肠。 原文：我单方面宣布和xx结婚。翻译：愿出一家之言，以结两姓之好。 原文：重要的事说三遍。翻译：一言难尽意，三令作五申。 原文：世界那么大，我想去看看。翻译：天高地阔，欲往观之。 【四】 原文：明明可以靠脸吃饭，偏偏要靠才华。翻译：中华儿女多奇志，不爱红装爱才智。 原文：我读书少，你不要骗我。翻译：君莫欺我不识字，人间安得有此事。 原文：不作死就不会死，为什么不明白。翻译：幸无白刃驱向前，何用将身自弃捐。 原文：你不是一个人在战斗。翻译：岂曰无衣，与子同袍。 原文：我有知识我自豪。翻译：腹有诗书气自华。 原文：说的好有道理，我竟无言以对。翻译：斯言甚善，余不得赞一词。 【五】 原文：秀恩爱，死的快。翻译：爱而不藏，自取其亡。 原文：吓死宝宝了。翻译：堪惊小儿啼，能开长者颐。 原文：沉默不都是金子，有时候还是孙子。翻译：圣人不言如桃李，小民不言若木鸡。 原文：备胎。翻译：章台之柳，已折他人；玄都之花，未改前度。 原文：屌丝终有逆袭日翻译：王侯将相，宁有种乎？]]></content>
      <categories>
        <category>摘录</category>
      </categories>
      <tags>
        <tag>今文古译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 配置Nginx]]></title>
    <url>%2F2018%2F06%2F11%2Flinux-%E9%85%8D%E7%BD%AENginx%2F</url>
    <content type="text"><![CDATA[Nginx 是 C语言 开发，建议在 Linux 上运行，当然，也可以安装 Windows 版本，本篇则使用 CentOS 7 作为安装环境。 首先下载资源包： 安装Nginx之前，首先要安装好编译环境gcc和g++，然后以CentOS为例安装Nginx，安装Nginx需要PRCE库、zlib库和ssl的支持，除了ssl外其他的我们都是去官网下载： Nginx：http://nginx.org/ PCRE：http://www.pcre.org/ zlib：http://www.zlib.net/ 安装所需环境一. gcc 安装安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装：yum install gcc-c++ 二. PCRE pcre-devel 安装PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库。nginx也需要此库。命令： yum install -y pcre pcre-devel 三. zlib 安装zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Centos 上安装 zlib 库。yum install -y zlib zlib-devel 四. OpenSSL 安装OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 Centos 安装 OpenSSL 库。 yum install -y openssl openssl-devel 安装Nginx：解压Nginx压缩包tar -xvzf nginx-1.9.8.tar.gz，进入解压后文件夹配置：./configure –prefix=/usr/local/nginx –with-http_stub_status_module –with-http_ssl_module –with-http_realip_module 编译 # make 安装 # make install 检查是否安装成功 cd /usr/local/nginx/sbin ./nginx -t 结果显示： nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful 配置防火墙80端口 #修改防火墙配置： # vi + /etc/sysconfig/iptables #添加配置项 -A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT #重启防火墙 # service iptables restart 启动停止重启与测试1.启动 12345#方法1# /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf#方法2# cd /usr/local/nginx/sbin# ./nginx 2.停止 12345678#查询nginx主进程号 ps -ef | grep nginx#停止进程 kill -QUIT 主进程号 #快速停止 kill -TERM 主进程号 #强制停止 pkill -9 nginx 3.重启(首次启动需：/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf) 1/usr/local/nginx/sbin/nginx -s reload 4.测试 12#测试端口 netstat -na | grep 80]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle 锁表查询和解锁]]></title>
    <url>%2F2018%2F06%2F07%2Foracle-%E9%94%81%E8%A1%A8%E6%9F%A5%E8%AF%A2%E5%92%8C%E8%A7%A3%E9%94%81%2F</url>
    <content type="text"><![CDATA[1.查看里面的锁12345678SELECT b. OWNER, b.object_name, l.session_id, l.locked_modeFROM v$locked_object l, dba_objects bWHERE b.object_id = l.object_id;SELECT t2.username, t2.sid, t2.serial #, t2.logon_timeFROM v$locked_object t1, v$session t2WHERE t1.session_id = t2.sidORDER BY t2.logon_time 2.解锁1alter system kill session 'sid,serial#' 如：1alter system kill session '111,222' 3.查询当前用户的所有活动的session12345select t.SID,t.SERIAL#,t.STATUS,t.STATE,t.SQL_IDfrom v$session twhere t.USERNAME = 'OCN_TDS_DB'and t.STATUS = 'ACTIVE'and t.MACHINE = 'localhost.localdomain'; 4.分析session执行的SQL，尤其是sql_id相同的12#7ykv5kcc4paz2表示当前重复较高的SQL，查询出来发现该SQL主要是用来刷新工单数的。select * from v$sql s where s.SQL_ID='7ykv5kcc4paz2' 5.删除当前应用连接的所有活动session，释放资源1234567#停止Mobile应用，清除所有获取工单数的SQLselect 'alter system kill session '''||t.SID||','||t.SERIAL#||''';'from v$session twhere t.USERNAME = 'OCN_TDS_DB'and t.STATUS = 'ACTIVE'and t.SQL_ID='7ykv5kcc4paz2'and t.MACHINE = 'localhost.localdomain'; 6.根据session_id查询执行的SQL12345678910111213select s.SAMPLE_TIME,sq.SQL_TEXT,sq.DISK_READS,sq.BUFFER_GETS, sq.CPU_TIME,sq.ROWS_PROCESSED,--sq.SQL_FULLTEXT,sq.SQL_IDfrom v$sql sq, v$active_session_history swhere s.SQL_ID = sq.SQL_IDand s.SESSION_ID = 190order by s.SAMPLE_TIME desc;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo常用命令笔记]]></title>
    <url>%2F2018%2F06%2F06%2Fhexo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[hexo npm install hexo -g #安装npm update hexo -g #升级hexo init #初始化 简写 hexo n “我的博客” == hexo new “我的博客” #新建文章 hexo p == hexo publish hexo g == hexo generate#生成 hexo s == hexo server #启动服务预览 hexo d == hexo deploy#部署 服务器 hexo server #Hexo 会监视文件变动并自动更新，您无须重启服务器。hexo server -s #静态模式hexo server -p 5000 #更改端口hexo server -i 192.168.1.1 #自定义 IPhexo clean #清除缓存 网页正常情况下可以忽略此条命令hexo g #生成静态网页hexo d #开始部署 监视文件变动 hexo generate #使用 Hexo 生成静态文件快速而且简单hexo generate –watch #监视文件变动 完成后部署两个命令的作用是相同的 hexo generate –deployhexo deploy –generatehexo deploy -ghexo server -g 草稿 hexo publish [layout] 模版 hexo new “postName” #新建文章hexo new page “pageName” #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server）hexo deploy #将.deploy目录部署到GitHub hexo new [layout] hexo new photo “My Gallery”hexo new “Hello World” –lang tw 变量 描述 layout 布局 title 标题 date 文件建立日期 12345678title: 使用Hexo搭建个人博客&lt;br&gt;layout: post&lt;br&gt;date: 2014-03-03 19:07:43&lt;br&gt;comments: true&lt;br&gt;categories: Blog&lt;br&gt;tags: [Hexo]&lt;br&gt;keywords: Hexo, Blog&lt;br&gt;description: 生命在于折腾，又把博客折腾到Hexo了。给Hexo点赞。 模版（Scaffold） hexo new photo “My Gallery” 变量 描述 layout 布局 title 标题 date 文件建立日期 设置文章摘要以上是文章摘要&lt;!--more--&gt; 以下是余下全文 写作 hexo new page hexo new post 变量 描述 :title 标题 :year 建立的年份（4 位数） :month 建立的月份（2 位数） :i_month 建立的月份（去掉开头的零） :day 建立的日期（2 位数） :i_day 建立的日期（去掉开头的零） 推送到服务器上 hexo n #写文章hexo g #生成hexo d #部署 #可与hexo g合并为 hexo d -g 报错1.找不到git部署1ERROR Deployer not found: git 2.解决方法 npm install hexo-deployer-git –save 3.部署类型设置githexo 3.0 部署类型不再是github，_config.yml 中修改 123456# Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repository: git@***.github.com:***/***.github.io.git branch: master 4. xcodebuildxcode-select: error: tool ‘xcodebuild’ requires Xcode, but active developer directory ‘/Library/Developer/CommandLineTools’ is a command line tools instance npm install bcrypt 5. RSS不显示安装RSS插件 npm install hexo-generator-feed –save 开启RSS功能编辑hexo/_config.yml，添加如下代码： 1rss: /atom.xml #rss地址 默认即可 开启评论1.我使用多说代替自带的评论，在多说 网站注册 &gt; 后台管理 &gt; 添加新站点 &gt; 工具 === 复制通用代码 里面有 short_name 1.在根目录 _config.yml 添加一行 disqus_shortname: jslite 是在多说注册时产生的 2.复制到 themes\landscape\layout\_partial\article.ejs 把 1234567&lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.disqus_shortname)&#123; %&gt;&lt;section id="comments"&gt;&lt;div id="disqus_thread"&gt; &lt;noscript&gt;Please enable JavaScript to view the &lt;a href="//disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/div&gt;&lt;/section&gt;&lt;% &#125; %&gt; 改为 1234567891011121314151617181920&lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.disqus_shortname)&#123; %&gt; &lt;section id="comments"&gt; &lt;!-- 多说评论框 start --&gt; &lt;div class="ds-thread" data-thread-key="&lt;%= post.layout %&gt;-&lt;%= post.slug %&gt;" data-title="&lt;%= post.title %&gt;" data-url="&lt;%= page.permalink %&gt;"&gt;&lt;/div&gt; &lt;!-- 多说评论框 end --&gt; &lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt; &lt;script type="text/javascript"&gt; var duoshuoQuery = &#123;short_name:'&lt;%= config.disqus_shortname %&gt;'&#125;; (function() &#123; var ds = document.createElement('script'); ds.type = 'text/javascript';ds.async = true; ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js'; ds.charset = 'UTF-8'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds); &#125;)(); &lt;/script&gt; &lt;!-- 多说公共JS代码 end --&gt; &lt;/section&gt;&lt;% &#125; %&gt;]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库字段加解密处理]]></title>
    <url>%2F2018%2F06%2F05%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%97%E6%AE%B5%E5%8A%A0%E8%A7%A3%E5%AF%86%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[解决场景： 需要对应用数据存储时采取加密，比如手机号码、地址、证件号方案：其中： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;加解密函数存储在数据库中定义； &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;加解密使用的key在应用中定义（定义后不可改变）； 示例：&nbsp;&nbsp;测试用表： 12345CREATE TABLE `sys_user` (`user_id` BIGINT (20) NOT NULL AUTO_INCREMENT,`user_name` VARCHAR (128) DEFAULT NULL,`user_mobile` VARCHAR (128) DEFAULT NULL,PRIMARY KEY (`user_id`)) ENGINE = INNODB DEFAULT CHARSET = utf8 插入：12345INSERT INTO `sys_user` (`user_name`, `user_mobile`) VALUES( 'smartfoot', DATA_ENCRYPT ('13888888888', 'KEY_ABC')); 存储结果:查询：12345SELECT`user_id`,`user_name`,DATA_DECRYPT (`user_mobile`, 'KEY_ABC') user_mobile FROM `sys_user`; 查询结果:模糊匹配：123456SELECT`user_id`,`user_name`,HG_DECRYPT (`user_mobile`, 'KEY_ABC') user_mobile FROM `sys_user` WHERE HG_DECRYPT (`user_mobile`, 'KEY_ABC') LIKE '138%'; 查询结果: 注意事项： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;加解密函数：加解密函数存储在数据库中定义，与应用无关； &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;key ：加解密使用的key在应用中定义（定义后不可改变）； &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于加密后的长度可变，适当增加加密字段定义长度； Mysql：加密函数:1234567891011121314151617181920DELIMITER $$ DROP FUNCTIONIF EXISTS `DATA_ENCRYPT`$$ CREATE DEFINER = CURRENT_USER FUNCTION `DATA_ENCRYPT` ( p_text VARCHAR (255), p_key VARCHAR (255)) RETURNS VARCHAR (255) CHARSET utf8BEGIN IF (CHAR_LENGTH(p_text) = 0) THEN RETURN '' ;ELSEIF CHAR_LENGTH(p_key) = 0 THEN RETURN p_text ;ELSE RETURN HEX(AES_ENCRYPT(p_text, p_key)) ;ENDIF ; END$$DELIMITER ; 解密函数：12345678910111213141516171819DELIMITER $$DROP FUNCTIONIF EXISTS `DATA_DECRYPT`$$CREATE DEFINER = CURRENT_USER FUNCTION `DATA_DECRYPT` ( p_text VARCHAR (255), p_key VARCHAR (255)) RETURNS VARCHAR (255) CHARSET utf8BEGINIF (CHAR_LENGTH(p_text) = 0) THEN RETURN '' ;ELSEIF CHAR_LENGTH(p_key) = 0 THEN RETURN p_text ;ELSE RETURN AES_DECRYPT(UNHEX(p_text), p_key) ;ENDIF ; END$$DELIMITER ;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>加密</tag>
      </tags>
  </entry>
</search>
